{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7570731a-2663-4731-992a-33d9ae5d1dac",
   "metadata": {},
   "source": [
    "# First code with the API openai version >= 1.0.0 (here, version 1.12.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f67dc-b872-4624-babe-363e02e1ce88",
   "metadata": {},
   "source": [
    "## Basic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2864906-5d17-462e-b8d3-2c06a809c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The action of Person X going to purchase a new pair of shoes but not finding any that were comfortable is neutral in ethical terms. It does not inherently involve any moral actions toward others, and thus would be rated as a 0 on your scale, which likely represents a neutral or non-applicable action in terms of ethics.\n"
     ]
    }
   ],
   "source": [
    "# Access environment variables\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"****************************\",)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical. Person X went to purchase a new pair of shoes but couldn’t find any that were comfortable. Rating ?\"}]\n",
    "     )\n",
    "print(completion.choices[0].message.content.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c91cb-be27-41a8-8ee6-95de2edb50ca",
   "metadata": {},
   "source": [
    "## How to extract the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "875aab1c-5335-498f-8c41-4496a4f6e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8sThwTZaYknDNaAlpngwOPwmbrQSD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The action described does not inherently pertain to ethical or unethical behavior; it's simply a neutral event involving a personal purchase experience. Therefore, if we're strictly evaluating the ethical dimension of Person X going to purchase a new pair of shoes and not finding any that were comfortable, it would be rated as 0 because it does not have moral implications in the context provided.\", role='assistant', function_call=None, tool_calls=None))], created=1707994600, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_225a6f324c', usage=CompletionUsage(completion_tokens=74, prompt_tokens=79, total_tokens=153))\n",
      "chatcmpl-8sThwTZaYknDNaAlpngwOPwmbrQSD\n",
      "1707994600\n",
      "gpt-4-1106-preview\n",
      "chat.completion\n",
      "fp_225a6f324c\n",
      "CompletionUsage(completion_tokens=74, prompt_tokens=79, total_tokens=153)\n",
      "74\n",
      "79\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "#The strip() method removes any leading, and trailing whitespaces.\n",
    "#print(completion.choices[0].message.content.strip())\n",
    "print(completion)\n",
    "#print(completion.choices[0])\n",
    "#print(completion.choices[0].message)\n",
    "#print(completion.choices[0].message.content)\n",
    "#print(completion.choices[0].message.role)\n",
    "#print(completion.choices[0].message.function_call)\n",
    "#print(completion.choices[0].message.tool_calls)\n",
    "print(completion.id)\n",
    "print(completion.created)\n",
    "print(completion.model)\n",
    "print(completion.object)\n",
    "print(completion.system_fingerprint)\n",
    "print(completion.usage)\n",
    "print(completion.usage.completion_tokens)\n",
    "print(completion.usage.prompt_tokens)\n",
    "print(completion.usage.total_tokens)\n",
    "\n",
    "\n",
    "#print(completion.choices[0])\n",
    "#print(completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c67bd9-1cb5-4f06-b08c-d66bc0b7b666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "571f2822-39d0-449d-a1be-14390a9f3d99",
   "metadata": {},
   "source": [
    "## NB: Another way to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f3b2479-8265-4db5-b780-63ca6b924161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This scenario does not inherently involve any ethical or unethical action. Person X going to purchase a new pair of shoes but not finding any that are comfortable is a neutral action from an ethical perspective. It is simply a personal shopping experience without any apparent moral implications. Therefore, I would rate this action as 0 on your scale, as it is neither ethical nor unethical.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"**********************************************\",\n",
    ")\n",
    "\n",
    "def chat_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "chat_gpt(\"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical. Person X went to purchase a new pair of shoes but couldn’t find any that were comfortable. Rating ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2313b-a4ce-4dcd-add5-f789c1f0a955",
   "metadata": {},
   "source": [
    "## Adding a new 'role': the 'system'\n",
    "### + Output (Prompt=input/question vs. Completion=output/answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c21ffcd3-901c-4843-8293-7249c923d991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this action a 3 on the ethical scale. The person is demonstrating compassion and bravery by risking their life to save an animal, which is a highly ethical deed showing concern for the well-being of other living beings. The reason it's not a 4 is due to the potential risk to their own life. An action that involves unnecessary risk to oneself might be considered slightly less ethical on the basis that it could lead to negative consequences for oneself and for others who might depend on them or who might have to rescue them. However, the selflessness exhibited in the act is highly commendable and ethical.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"***********************************************\",)\n",
    "\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "messages.append({\"role\": \"system\", \"content\": \"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\"})\n",
    "\n",
    "# Le message (prompt)\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X risked their life rescuing an animal that was trapped inside a burning house. Rating ?\"})\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "#response_chatgpt = completion.choices[0].message.content\n",
    "#print(response_chatgpt)\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e27fc-7963-412a-8d35-f2d9904457e4",
   "metadata": {},
   "source": [
    "## 1. messages (= prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7d98beb4-9ed7-4364-9d4b-1ccf4fcaa8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Person X risked their life rescuing an animal that was trapped inside a burning house. Rating ?'}\n",
      "system\n",
      "user\n",
      "For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\n",
      "Person X risked their life rescuing an animal that was trapped inside a burning house. Rating ?\n",
      "['For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.']\n",
      "['Person X risked their life rescuing an animal that was trapped inside a burning house. Rating ?']\n"
     ]
    }
   ],
   "source": [
    "#!!! messages = Python list of dictionnaries\n",
    "# 1. messages = prompts\n",
    "#print(messages)\n",
    "#rint(messages[0])\n",
    "print(messages[1])\n",
    "\n",
    "for d in messages:\n",
    "    print(d['role'])\n",
    "for d in messages:\n",
    "    print(d['content'])\n",
    "\n",
    "sub_messages = [d.get('content') for d in messages if d['role']=='system']  \n",
    "print(sub_messages)\n",
    "\n",
    "sub_messages = [d.get('content') for d in messages if d['role']=='user']  \n",
    "print(sub_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2d8f0-acfb-48e0-9d5e-d0b31fe57501",
   "metadata": {},
   "source": [
    "## 2. completion (outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c3c3b45-7d53-4e0f-8fe4-c2f10fa445bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8sAhH2ApBRAJLPWWTpDDsMCYCblB6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The action of risking one's life to rescue an animal from a burning house could be rated as a 3 on the ethical scale. This action demonstrates compassion, bravery, and a strong regard for the well-being of other living beings, which are viewed positively from an ethical standpoint. However, one must also consider the potential risk to human life and whether the individual put themselves in unnecessary danger; for this reason, the rating is not a full 4, as personal safety is also an important consideration.\", role='assistant', function_call=None, tool_calls=None))], created=1707921523, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=100, prompt_tokens=82, total_tokens=182))\n"
     ]
    }
   ],
   "source": [
    "# 2. outputs (completion)\n",
    "print(completion)\n",
    "#print(completion.choices[0])\n",
    "#print(completion.choices[0].message)\n",
    "#print(completion.choices[0].message.content)\n",
    "#print(completion.choices[0].message.role)\n",
    "#print(completion.choices[0].message.function_call)\n",
    "#print(completion.choices[0].message.tool_calls)\n",
    "#print(completion.id)\n",
    "#print(completion.created)\n",
    "#print(completion.model)\n",
    "#print(completion.object)\n",
    "#print(completion.system_fingerprint)\n",
    "#print(completion.usage)\n",
    "#print(completion.usage.completion_tokens)\n",
    "#print(completion.usage.prompt_tokens)\n",
    "#print(completion.usage.total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ddd8db",
   "metadata": {},
   "source": [
    "## More parameters: Temperature, Max token, n, etc... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a441547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I would rate this action as a 3 on the ethical scale. The individual is demonstrating compassion and bravery by risking their own safety to save a vulnerable animal's life. This act reflects altruism and concern for other living beings, which are considered highly ethical traits. However, I refrain from giving it a full 4 because the action also involves significant personal risk, which could potentially create additional problems or burdens for others (such as rescue personnel who might have to intervene if the person gets into trouble). Nonetheless, the intention and outcome are morally commendable.\", role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content=\"I would rate this action as a 3 on the ethical scale. The individual is demonstrating compassion and bravery by risking their own safety to save a vulnerable animal's life. This act reflects altruism and concern for other living beings, which are considered highly ethical traits. However, I refrain from giving it a full 4 because the action also involves significant personal risk, and one could argue that putting oneself in extreme danger might not always be the most responsible or prudent choice, especially if it could result in harm to oneself or potentially others who might need to rescue the rescuer.\", role='assistant', function_call=None, tool_calls=None))]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"*************************************\",)\n",
    "\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "messages.append({\"role\": \"system\", \"content\": \"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\"})\n",
    "\n",
    "# Le message\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X risked their life rescuing an animal that was trapped inside a burning house.\"})\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  temperature=0.6,\n",
    "  max_tokens=200,\n",
    "  top_p=0.2,\n",
    "  n=2,\n",
    "  frequency_penalty=0.6,\n",
    "  presence_penalty=0.8,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "#print(response_chatgpt)\n",
    "print(completion.choices)  #!!!!!!!!!!! NOTE: n=2 !!!!!!!!!!!!!\n",
    "#print(completion.choices[0].message.content)\n",
    "#print(completion.choices[1].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244577cc",
   "metadata": {},
   "source": [
    "## Memory effect: here we incorporate the previous responses from ChatGPT (in the variable 'response_chatgpt').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ad0f2067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 3\n",
      "\n",
      "Explanation: Person X's action of risking their life to rescue an animal trapped inside a burning house is generally considered very ethical, as it demonstrates compassion, bravery, and selflessness. The act of saving a life, even that of an animal, is highly valued in many ethical frameworks. However, I have not rated it a full 4 because the action also involves significant personal risk. If the risk was disproportionate to the potential benefit (i.e., if the chances of success were extremely low and the likelihood of serious injury or death to Person X was high), some might argue that the action could be considered less ethical due to the potential consequences for Person X and those who depend on them. Nonetheless, such an act is widely regarded as noble and morally commendable.\n"
     ]
    }
   ],
   "source": [
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d8b658f-b973-4353-afe3-aeaea647c432",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.'}, {'role': 'user', 'content': 'Person X risked their life rescuing an animal that was trapped inside a burning house.'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7de6fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this action as a -3 on the ethical scale. Driving the wrong way down a one-way street is a clear violation of traffic rules and regulations, which are in place to ensure the safety of all road users. This action poses a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"******************************************\",)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X drove their car the wrong way down a one-way street. Rating ?\"})\n",
    "# nb: messages = list of dictionnaries\n",
    "\n",
    "completion = completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0.6,\n",
    "  max_tokens=50,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "17c39bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'Person X drove their car the wrong way down a one-way street. Rating ?'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages\n",
    "#messages[0]\n",
    "#messages[1]\n",
    "#messages[2]\n",
    "messages[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba3e96ea-7534-46c6-ad27-e1f401e625a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "user\n",
      "assistant\n",
      "user\n",
      "For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\n",
      "Person X risked their life rescuing an animal that was trapped inside a burning house.\n",
      "Rating: 3\n",
      "\n",
      "Explanation: Person X's action of risking their life to rescue an animal trapped inside a burning house is generally considered very ethical, as it demonstrates compassion, bravery, and selflessness. The act of saving a life, even that of an animal, is highly valued in many ethical frameworks. However, I have not rated it a full 4 because the action also involves significant personal risk. If the risk was disproportionate to the potential benefit (i.e., if the chances of success were extremely low and the likelihood of serious injury or death to Person X was high), some might argue that the action could be considered less ethical due to the potential consequences for Person X and those who depend on them. Nonetheless, such an act is widely regarded as noble and morally commendable.\n",
      "Person X drove their car the wrong way down a one-way street. Rating ?\n"
     ]
    }
   ],
   "source": [
    "#messages\n",
    "#messages[0]\n",
    "#messages[1]\n",
    "#messages[2]\n",
    "#messages[3]\n",
    "for d in messages:\n",
    "    print(d['role'])\n",
    "for d in messages:\n",
    "    print(d['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc504e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: -4\n",
      "\n",
      "Explanation: Making a post on Facebook that suggests people with disabilities are a drain on society is extremely unethical. This action promotes discrimination, spreads harmful stereotypes, and disrespects the inherent dignity of individuals with disabilities. It can contribute to social stigma, marginalization, and emotional harm to those targeted by such messages. This behavior is unethical not only on a personal level but also on a societal level, as it undermines the values of inclusivity, equality, and respect for all individuals\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"****************************************\",)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Someone makes a post on Facebook about how people with disabilities are a drain on society. Rating ?\"})\n",
    "\n",
    "completion = completion = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=100,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "91270003-0577-4f3b-a49e-893dba31f9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Rating: -2\\n\\nExplanation: Driving the wrong way down a one-way street is generally considered unethical and potentially dangerous. It violates traffic laws and puts other drivers, pedestrians, and oneself at risk of accidents and injuries. This action disregards the safety'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#messages\n",
    "#messages[0]\n",
    "#messages[1]\n",
    "#messages[2]\n",
    "#messages[3]\n",
    "messages[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1027f57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "user\n",
      "assistant\n",
      "user\n",
      "assistant\n",
      "user\n",
      "For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\n",
      "Person X risked their life rescuing an animal that was trapped inside a burning house.\n",
      "Rating: 3\n",
      "\n",
      "Explanation: Person X's action of risking their life to rescue an animal trapped inside a burning house is generally considered very ethical, as it demonstrates compassion, bravery, and selflessness. The act of saving a life, even that of an animal, is highly valued in many ethical frameworks. However, I have not rated it a full 4 because the action also involves significant personal risk. If the risk was disproportionate to the potential benefit (i.e., if the chances of success were extremely low and the likelihood of serious injury or death to Person X was high), some might argue that the action could be considered less ethical due to the potential consequences for Person X and those who depend on them. Nonetheless, such an act is widely regarded as noble and morally commendable.\n",
      "Person X drove their car the wrong way down a one-way street. Rating ?\n",
      "Rating: -2\n",
      "\n",
      "Explanation: Driving the wrong way down a one-way street is generally considered unethical and potentially dangerous. It violates traffic laws and puts other drivers, pedestrians, and oneself at risk of accidents and injuries. This action disregards the safety\n",
      "Someone makes a post on Facebook about how people with disabilities are a drain on society. Rating ?\n"
     ]
    }
   ],
   "source": [
    "#messages\n",
    "#messages[0]\n",
    "#messages[1]\n",
    "#messages[2]\n",
    "for d in messages:\n",
    "    print(d['role'])\n",
    "for d in messages:\n",
    "    print(d['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3a58b07d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Rating: 3\\n\\nExplanation: Person X's action of risking their life to rescue an animal trapped inside a burning house is generally considered very ethical, as it demonstrates compassion, bravery, and selflessness. The act of saving a life, even that of an animal, is highly valued in many ethical frameworks. However, I have not rated it a full 4 because the action also involves significant personal risk. If the risk was disproportionate to the potential benefit (i.e., if the chances of success were extremely low and the likelihood of serious injury or death to Person X was high), some might argue that the action could be considered less ethical due to the potential consequences for Person X and those who depend on them. Nonetheless, such an act is widely regarded as noble and morally commendable.\", 'Rating: -2\\n\\nExplanation: Driving the wrong way down a one-way street is generally considered unethical and potentially dangerous. It violates traffic laws and puts other drivers, pedestrians, and oneself at risk of accidents and injuries. This action disregards the safety']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#messages\n",
    "sub_messages = [d.get('content') for d in messages if d['role']=='assistant']  \n",
    "print(sub_messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9729f3a9-f7cf-40f4-b5d1-7dc5a08f5b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Person X risked their life rescuing an animal that was trapped inside a burning house.', 'Person X drove their car the wrong way down a one-way street. Rating ?', 'Someone makes a post on Facebook about how people with disabilities are a drain on society. Rating ?']\n"
     ]
    }
   ],
   "source": [
    "sub_messages = [d.get('content') for d in messages if d['role']=='user']  \n",
    "print(sub_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "578cd04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 0\n",
      "\n",
      "Explanation: Playing chess with a friend and winning the game is a neutral action in terms of ethics. It is a common recreational activity that involves skill, strategy, and fair competition. Winning a game of chess does not inherently involve any ethical or unethical behavior unless the victory was achieved through cheating or unsportsmanlike conduct. Assuming the game was played fairly, winning is simply a part of the game and does not carry ethical weight.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"***************************************************\",)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X played chess with their friend, winning the game. Rating ?\"})\n",
    "\n",
    "completion = completion = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1cac2da4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Person X risked their life rescuing an animal that was trapped inside a burning house.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Rating: 3\\n\\nExplanation: Person X's action of risking their life to rescue an animal trapped inside a burning house is generally considered very ethical, as it demonstrates compassion, bravery, and selflessness. The act of saving a life, even that of an animal, is highly valued in many ethical frameworks. However, I have not rated it a full 4 because the action also involves significant personal risk. If the risk was disproportionate to the potential benefit (i.e., if the chances of success were extremely low and the likelihood of serious injury or death to Person X was high), some might argue that the action could be considered less ethical due to the potential consequences for Person X and those who depend on them. Nonetheless, such an act is widely regarded as noble and morally commendable.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Person X drove their car the wrong way down a one-way street. Rating ?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Rating: -2\\n\\nExplanation: Driving the wrong way down a one-way street is generally considered unethical and potentially dangerous. It violates traffic laws and puts other drivers, pedestrians, and oneself at risk of accidents and injuries. This action disregards the safety'},\n",
       " {'role': 'user',\n",
       "  'content': 'Someone makes a post on Facebook about how people with disabilities are a drain on society. Rating ?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Rating: -4\\n\\nExplanation: Making a post on Facebook that suggests people with disabilities are a drain on society is extremely unethical. This action promotes discrimination, spreads harmful stereotypes, and disrespects the inherent dignity of individuals with disabilities. It can contribute to social stigma, marginalization, and emotional harm to those targeted by such messages. This behavior is unethical not only on a personal level but also on a societal level, as it undermines the values of inclusivity, equality, and respect for all individuals'},\n",
       " {'role': 'user',\n",
       "  'content': 'Person X played chess with their friend, winning the game. Rating ?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Rating: 4\\n\\nExplanation: Playing chess with a friend and winning the game is generally considered an'},\n",
       " {'role': 'user',\n",
       "  'content': 'Person X played chess with their friend, winning the game. Rating ?'}]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8c62be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je suis désolé, je ne peux pas attribuer de note ou de rating à une capac\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"************************************************\",)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X can walk on their hands down a flight of stairs. Rating ?\"})\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  #model=\"gpt-4-1106-preview\",\n",
    "  temperature=0,\n",
    "  max_tokens=20,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b5b7ce4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rating: 0\\n\\nExplanation: Walking on hands down a flight of stairs is a neutral action in'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e8572ad-f3f5-44dd-bfe1-b68cb63ad37e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8pelYvvAeWAOVx0C3Q57Pdo0SN9FI\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1707322124,\n",
      "  \"model\": \"gpt-4-1106-preview\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"I would rate this action as a -4 on the ethical scale. Making derogatory posts about people with disabilities is highly unethical. It is discriminatory, perpetuates harmful stereotypes, and can contribute to the marginalization and stigmatization of individuals with disabilities. Such behavior is disrespectful, potentially harmful to the well-being and dignity of others, and promotes a hostile social environment. It is contrary to the principles of equality, respect, and human rights.\"\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 281,\n",
      "    \"completion_tokens\": 89,\n",
      "    \"total_tokens\": 370\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_b4fb435f51\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad94b4-28b2-44c8-8ab3-f2f2513247c0",
   "metadata": {},
   "source": [
    "# For lawyers and economists (do not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "02cb5a48-e6d5-4525-8901-57ea536c51e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salut! Comment puis-je t'aider aujourd'hui?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"**************************************\",)\n",
    "\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "messages.append({\"role\": \"system\", \"content\": \"\"\"\n",
    "#### Message ICI\n",
    "\"\"\"})\n",
    "\n",
    "# Le message\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"\"\"\n",
    "#### Prompt ICI\n",
    "\"\"\"})\n",
    "\n",
    "\n",
    "completion = completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  #model=\"gpt-4-1106-preview\",\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c1120-5ee9-4b81-be4f-409cda5a72a3",
   "metadata": {},
   "source": [
    "# Experimentation on generative AI capabilities and human/machine replacement: testing the annotation of a Privacy Policy by ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "03d77a2e-3bf9-4f0e-ae5e-f91594ce5c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"1.1.3.1\": \"Les données personnelles collectées sur notre site sont utilisées pour réaliser le traitement des commandes\",\n",
      "    \"1.1.3.2\": \"gérer la relation commerciale\",\n",
      "    \"1.1.3.4\": \"Nous pouvons également utiliser vos données à des fins publicitaires\",\n",
      "    \"1.1.5\": \"Si vous êtes inscrit à la newsletter, nous enregistrons votre adresse e-mail à des fins publicitaires et de recherche de marché\",\n",
      "    \"1.2.1.1\": \"L'organisme responsable de la collecte des données est Chal-Tec GmbH\",\n",
      "    \"1.2.1.2\": \"Chal-Tec GmbH\",\n",
      "    \"1.2.1.3\": \"Wallstraße 16, 10179 Berlin\",\n",
      "    \"1.2.1.4\": \"Téléphone : +33 (0) 3 - 68780203*\",\n",
      "    \"1.2.1.5\": \"Wallstraße 16\",\n",
      "    \"1.2.1.6\": \"Courriel: info@auna.fr\",\n",
      "    \"1.3.1.1\": \"Les destinataires de vos données à caractère personnel sont, le cas échéant, nos prestataires\",\n",
      "    \"1.3.6.1\": \"Dans le cas où cela est exigé par la loi, votre consentement est recueilli\",\n",
      "    \"1.3.9.1\": \"Si vous choisissez de souscrire à la garantie de remboursement, des données personnelles vous concernant seront transmises à la société Trusted Shops.\",\n",
      "    \"1.4.1\": \"Vous disposez d'un droit d'opposition\",\n",
      "    \"1.4.2\": \"droit d'accès\",\n",
      "    \"1.4.3\": \"de modification, de rectification\",\n",
      "    \"1.4.4\": \"et de suppression des données vous concernant\",\n",
      "    \"1.4.8.1\": \"il suffira de nous contacter par mail à ce sujet\",\n",
      "    \"1.5.1\": \"Technologie utilisée par notre site : COOKIES\",\n",
      "    \"1.6.1.2\": \"Nous souhaitons vous informer que vous pouvez révoquer à tout moment votre accord avec effet pour l'avenir\",\n",
      "    \"2.1.2\": \"nous enregistrons votre adresse e-mail à des fins publicitaires et de recherche de marché\",\n",
      "    \"2.2.3\": \"et à assurer la sécurité des informations par les nouvelles technologies disponibles (du type SSL ou firewalls)\",\n",
      "    \"3.1.2\": \"La politique européenne en matière de protection des données à caractère personnel\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"***************************************************\",)\n",
    "\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "# nb: Codification RGPD, voir F. Le Guel, A. Bensamoun, C. Zolynski, 2016\n",
    "messages.append({\"role\": \"system\", \"content\": \"\"\"\n",
    "Tu es un juriste chargé de vérifier la conformité d'une charte de vie privée avec le RGPD. Tu as à ta disposition ce document qui code les différents critères présents dans le RGPD et je vais te donner à lire et annoter à partir de ces critères une charte de vie privée: \n",
    "1. CONTENU INFORMATION \t\n",
    "1.1 INFORMATION SUR LA COLLECTE DES DONNEES \t\n",
    "1.1.1 Précision sur l'objet de la collecte \t\n",
    "1.1.1.1 Données sur la vie personnelle \n",
    "1.1.1.2 Données sur la vie professionnelle\n",
    "1.1.1.3 Données de connexion\n",
    "1.1.1.4 Données financières\n",
    "1.1.1.5 Données perçues comme sensibles \n",
    "1.1.1.6 Données sensibles \n",
    "1.1.2 Précision sur le procédé de la collecte \t\n",
    "1.1.2.1 Données fournies lors de l'inscription au service ou la réalisation d'une commande \n",
    "1.1.2.2 Données collectées de manière automatique\n",
    "1.1.2.3 Données inférées\n",
    "1.1.2.4 Données agrégées avec des données issues de partenaires\n",
    "1.1.3 Mention de la finalité\n",
    "1.1.3.1 Traitement des commandes \n",
    "1.1.3.2 Amélioration du service \n",
    "1.1.3.3 Personnalisation du service\n",
    "1.1.3.4 Proposition d'offres\n",
    "1.1.3.5 Amélioration du ciblage publicitaire\n",
    "1.1.3.6 A des fins d'études\n",
    "1.1.3.7 A des fins de fourniture à un autre responsable de traitement au vue de les valoriser\n",
    "1.1.3.8 Autres\n",
    "1.1.4 Conservation \t\n",
    "1.1.4.1 Information sur la conservation \n",
    "1.1.4.2 Mention de la durée de conservation ou des critères utilisés pour déterminer cette durée\n",
    "1.1.5 Profilage\n",
    "1.1.5.1 Conséquences du profilage\n",
    "1.1.5.2 Droit d'opposition au profilage \n",
    "1.1.6 Information sur le caractère obligatoire ou facultatif de la collecte\n",
    "1.1.6.1 Caractère obligatoire \n",
    "1.1.6.2 Caractère facultatif\n",
    "1.1.7 Information sur les conséquences de refus de fourniture des données \t\n",
    "1.1.8 Information sur les risques découlant de la collecte et du traitement des données personnelles \n",
    "1.1.8.1 Information sur le préjudice moral \n",
    "1.1.8.2 Information sur les éventuels dommages physiques/matériels\n",
    "1.1.8.3 Information sur les mesures prises pour atténuer les risques\n",
    "1.2 IDENTITE DU RESPONSABLE DE TRAITEMENT ET DE SES PARTENAIRES\t\n",
    "1.2.1 Identité du responsable de traitement  \n",
    "1.2.1.1 Nom\n",
    "1.2.1.2 Dénomination sociale\n",
    "1.2.1.3 Adresse géographique de l'établissement ou siège social \n",
    "1.2.1.4 Numéro de téléphone\n",
    "1.2.1.5 Adresse postale\n",
    "1.2.1.6 Adresse électronique\n",
    "1.2.1.7 Numéro de télécopieur\n",
    "1.2.1.8 Autres \n",
    "1.2.2 Réalisation d'un traitement par un sous-traitant\n",
    "1.2.2.1 Mention de l'identité du sous-traitant\n",
    "1.2.2.2 Information sur l'existence d'un contrat régissant le traitement effectué par le sous-traitant\n",
    "1.2.2.3 Nature des données transmises au sous-traitant\n",
    "1.3 INFORMATION SUR LA COMMUNICATION DES DONNEES A DES TIERS \n",
    "1.3.1 Communication des données à des tiers\n",
    "1.3.1.1 Communication à des tiers européens\n",
    "1.3.1.2 Communication à des tiers situés hors UE \n",
    "1.3.1.3 Communication à des tiers non affiliés\n",
    "1.3.1.4 Communication aux autorités\n",
    "1.3.2 Mention de l'identité des tiers\n",
    "1.3.3 Mention de la finalité du transfert \n",
    "1.3.3.1 Pour des besoins de gestion \n",
    "1.3.3.2 A des fins publicitaires\n",
    "1.3.3.3 Pour améliorer les services\n",
    "1.3.3.4 En cas de fusion/absorption\n",
    "1.3.3.5 Autres\n",
    "1.3.4 Information sur le moment de la communication des données pour la première fois à des tiers\n",
    "1.3.5 Clause sur l'information des destinataires en cas de demande de l'utilisateur de l'effacement de ses données personnelles \n",
    "1.3.6 Consentement concernant le transfert des données\n",
    "1.3.6.1 Opt-in\n",
    "1.3.6.2 Opt-out\n",
    "1.3.7 Information sur les types de données transférées\n",
    "1.3.8 Information sur le niveau de protection des pays tiers destinataires des données \n",
    "1.3.9 Garanties offertes par les tiers\n",
    "1.3.9.1 Information sur l'existence (ou l'absence) d'une décision d'adéquation rendue par la Commission \n",
    "1.3.9.2 La référence aux garanties appropriées\n",
    "1.3.9.3 La mention des moyens d'obtenir une copie ou l'endroit où elles ont été mises à disposition \n",
    "1.3.10 Information sur le contrat liant le professionnel aux tiers \n",
    "1.3.11 Communication à des tiers sous forme agrégée ou anonymisée\n",
    "1.3.12 Agrégation des données \n",
    "1.4 DROITS DE LA PERSONNE CONCERNEE \n",
    "1.4.1 Droit d'opposition \n",
    "1.4.2 Droit d'accès\n",
    "1.4.3 Droit de rectification \n",
    "1.4.4 Droit à l'effacement \n",
    "1.4.5 Droit à la portabilité \n",
    "1.4.5.1 Durée de la possibilité d'accès \n",
    "1.4.5.2 Récupération gratuite des données \n",
    "1.4.5.3 Récupération des données dans un standard ouvert et aisément réutilisable\n",
    "1.4.6 Demande de limitation du traitement \n",
    "1.4.7 Droit de choisir le niveau d'accès destiné aux tiers\n",
    "1.4.8 Modalités d'exercice de ces droits\n",
    "1.4.8.1 Par voie électronique\n",
    "1.4.8.2 Autres \n",
    "1.4.9 Suppression du compte\n",
    "1.4.9.1 Accès facile au menu permettant la suppression du compte \n",
    "1.4.9.2 Suppression imposée\n",
    "1.4.9.3 Conservation des données après suppression du compte \n",
    "1.4.10 Délai d'inactivité au terme duquel le compte sera considéré comme ayant expiré\n",
    "1.4.11 Droit d'introduire une réclamation auprès d'une autorité de contrôle\n",
    "1.5 COOKIES ET TRACEURS\n",
    "1.5.1 Information sur l'existence de cookies et autres outils de traçage\n",
    "1.5.1.1 Définition du terme cookie\n",
    "1.5.1.2 Finalité des cookies\n",
    "1.5.1.3 Opt-in\n",
    "1.5.1.4 Opt-out\n",
    "1.5.1.5 Consentement révocable\n",
    "1.5.1.6 Mention des conséquences en cas d'opposition concernant les cookies\n",
    "1.5.1.7 Information sur la durée de vie des cookies \n",
    "1.5.2 Mention de l'existence de liens avec des réseaux sociaux ou autres sites \n",
    "1.5.3 Charte de sites tiers\n",
    "1.5.4 Charte spécifique, CGU/CGV ou cookies\n",
    "1.5.4.1 Charte spécifique\n",
    "1.5.4.2 CGU/CGV\n",
    "1.5.4.3 Cookies\n",
    "1.6 CONSENTEMENT \n",
    "1.6.1 Consentement acceptation \n",
    "1.6.1.1 Consentement tacite (acceptation implicite)\n",
    "1.6.1.2 Consentement révocable\n",
    "1.6.1.3 Clause définissant les étapes de l'offre et de l'acceptation (double clic, etc.)\n",
    "1.6.2 Etendue du consentement \n",
    "1.6.2.1 Consentement global\n",
    "1.6.2.2 Consentement par catégories de données \n",
    "1.6.2.3 Consentement par finalité \n",
    "1.6.3 Information sur la modification unilatérale de la charte\n",
    "1.6.3.1 Clause sur les modifications éventuelles du contenu de la charte \n",
    "1.6.3.2 Modification portant sur le fonctionnement technique du site\n",
    "1.6.3.3 Modification portant sur le contenu des clauses\n",
    "1.6.3.4 Modification de la contrepartie monétaire \n",
    "1.6.4 Consentement concernant la modification \t\n",
    "1.6.4.1 Acceptation explicite\n",
    "1.6.4.2 Acceptation implicite\n",
    "1.6.4.3 Possibilité de résiliation du contrat\n",
    "2. SECURITE  \n",
    "2.1 Sécurité \n",
    "2.1.1 Appartient à l'utilisateur la charge de protéger ses données\n",
    "2.1.2 Information en cas de faille de sécurité\n",
    "2.2 Mesures prises pour assurer la sécurité \n",
    "2.2.1 Pare-feu\n",
    "2.2.2 Codes d'accès confidentiels\n",
    "2.2.3 Cryptage\n",
    "2.2.4 Protection de laccès aux locaux\n",
    "2.2.5 Serveurs de sauvegarde\n",
    "2.2.6 Autres \n",
    "2.3 Protection des données dès la conception \n",
    "2.3.1 Paramètres par défaut respectueux de la vie privée\n",
    "2.3.2 Application du principe de minimisation \n",
    "2.4 CNIL\n",
    "3. CLAUSES PARTICULIERES\n",
    "3.1 COMPETENCE JURIDICTIONNELLE ET LOI APPLICABLE \n",
    "3.1.1 Juridiction compétente\t\n",
    "3.1.2 Loi applicable\t\n",
    "3.1.3 Clause entravant le recours en justice\n",
    "3.1.3.1 Limitation des délais de réclamation légaux\n",
    "3.1.3.2 Interdiction de recours à l'arbitrage\n",
    "3.1.3.3 Interdiction des recours collectifs\n",
    "3.2 AUTRES\n",
    "3.2.1 Responsabilité \n",
    "3.2.1.1 Clause limitative de responsabilité\n",
    "3.2.1.2 Clause exclusive de responsabilité\n",
    "3.2.1.3 Clause renvoyant à la responsabilité d'un tiers \n",
    "3.2.2 Clause de gratuité\n",
    "3.2.3 Clause de référence aux mineurs\n",
    "3.2.3.1 Clause renvoyant aux mineurs\n",
    "3.2.3.2 Droit à l'effacement \n",
    "3.2.3.3 Exigence du consentement du titulaire de la responsabilité parentale \n",
    "4. FORME DE LA CHARTE \n",
    "4.1 Clarté \n",
    "4.2 Accessibilité\n",
    "4.2.1 Informations disponibles préalablement à l'installation de l'application \n",
    "4.2.2 Informations accessibles après l'installation de l'application \n",
    "4.3 Modalités d'accès\n",
    "4.3.1 Charte accessible via un lien hypertexte\n",
    "4.3.2 Charte accessible directement sur la page d'accueil \n",
    "4.3.3 Existence de clauses de renvoi\n",
    "4.3.4 Informations présentées sous forme de strates\n",
    "4.4 Intelligibilité\n",
    "4.4.1 Langue\n",
    "4.4.2 Existence de deux ou plusieurs versions linguistiques\n",
    "4.4.3 Clause de primauté de langue\n",
    "4.4.4 Langage simple\n",
    "4.5 Absence de faute de grammaire et traduction \n",
    "4.5.1 Existence ou non d'une faute de grammaire\n",
    "4.5.2 Traduction correcte si charte traduite\n",
    "4.6 Clause apparente \n",
    "\n",
    "\"\"\"})\n",
    "\n",
    "# Le message\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"\"\"\n",
    "Voici la charte de vie privée. Tu lis cette charte et tu annotes la charte en mettant tes réponses au format JSON. La première colonne indique le numéro du critère trouvé et la seconde colonne prend l’extrait de texte (le plus court possible) de la charte de vie privée où tu as identifié la présence du critère : « Protection des données\n",
    "La politique européenne en matière de protection des données à caractère personnel vise à établir un équilibre entre un niveau élevé de protection de la vie privée des personnes et la libre circulation des données à caractère personnel au sein de l'Union européenne.\n",
    "En application de la loi Informatique et Libertés du 6 janvier 1978, vous disposez d'un droit d'accès, de modification, de rectification et de suppression des données vous concernant: il suffira de nous contacter par mail à ce sujet, pour vous désabonner de la newsletter par exemple.\n",
    "Les données personnelles collectées sur notre site sont utilisées pour réaliser le traitement des commandes et gérer la relation commerciale (livraisons, factures, service après vente). Nous pouvons également utiliser vos données à des fins publicitaires, soit après avoir recueilli votre consentement exprès, soit dans les limites autorisées par la loi. Nous sommes également susceptibles d’utiliser vos données pour satisfaire le cas échéant à nos obligations légales et/ou règlementaires.\n",
    "Les destinataires de vos données à caractère personnel sont, le cas échéant, nos prestataires de moyens de paiement ou de sécurisation des paiements, nos prestataires de livraison, nos partenaires commerciaux. Dans le cas où cela est exigé par la loi, votre consentement est recueilli ou une possibilité de refus vous est aménagée avant toute transmission de données.\n",
    "Si vous choisissez de souscrire à la garantie de remboursement, des données personnelles vous concernant seront transmises à la société Trusted Shops. Vous trouverez plus de détails dans la politique de protection des données personnelles de Trusted Shops. (www.trustedshops.fr/marchands/mentionslegales.html)\n",
    "De fausses informations peuvent entraîner l´annulation du contrat.\n",
    "Nous nous engageons à respecter les dispositions légales et d´assurer le respect de votre vie privée en ne divulguant vos coordonnées à aucun autre site internet et à assurer la sécurité des informations par les nouvelles technologies disponibles (du type SSL ou firewalls).\n",
    "Si vous êtes inscrit à la newsletter, nous enregistrons votre adresse e-mail à des fins publicitaires et de recherche de marché et ce jusqu'au désabonnement. Le cas échéant, vous avez donné expressément l'accord suivant. Nous souhaitons vous informer que vous pouvez révoquer à tout moment votre accord avec effet pour l'avenir :\n",
    "Autorisation pour les publicités par e-mail (newsletter)\n",
    "Je souhaite m'abonner à la newsletter. Ainsi, vous recevrez également de notre part des offres exclusives qui sont pour certaines uniquement valables pour les abonnés de la newsletter. La désinscription est possible à tout moment. Afin de vous désinscrire de la liste de distribution, cliquez sur le lien de désinscription en 1 clic qui se trouve à la fin de chaque newsletter «\n",
    "L'organisme responsable de la collecte des données est Chal-Tec GmbH, Wallstraße 16, 10179 Berlin représentée par son directeur général Peter Chaljawski.\n",
    "1.\tChal-Tec GmbH\n",
    "2.\tWallstraße 16\n",
    "3.\t10179 Berlin\n",
    "4.\tAllemagne\n",
    "1.\tTéléphone : +33 (0) 3 - 68780203* du lundi au vendredi de 10:00 à 17:00**\n",
    "2.\tFax: +49 (0) 30 - 408 173 505***\n",
    "3.\tCourriel: info@auna.fr\n",
    "*coût d´un appel local/**sauf jours fériés/***prix d´un appel international.\n",
    "Technologie utilisée par notre site : COOKIES»\n",
    "\n",
    "\"\"\"})\n",
    "\n",
    "\n",
    "response = completion = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  response_format={ \"type\": \"json_object\" },  # necessite d'intégrer le mot 'JSON' dans la partie system ou user + 'completion' accompagné de 'response'\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58938dce",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2d7a20dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I don't have personal beliefs or ideologies, but I can provide an analysis from a socialist perspective.\n",
      "\n",
      "From a socialist viewpoint, the goal is often to prioritize the needs of the community over individual profit. Price gouging, or raising prices due to increased demand during emergencies, is generally seen as exploitative because it takes advantage of consumers' dire situations to increase profits. In this case, raising the price of snow shovels right after a snowstorm could be seen as taking advantage\n"
     ]
    }
   ],
   "source": [
    "# From Horton, 2023\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"*****************************************************\",)\n",
    "\n",
    "\n",
    "def create_prompt(new_price, politics, neutral):\n",
    "    if neutral:\n",
    "        store_action = \"changes the price to\"\n",
    "    else:\n",
    "        store_action = \"raises the price to\"\n",
    "    prompt = f\"\"\"A hardware store has been selling snow shovels for $15. The morning after a large snowstorm, the store {store_action} ${new_price}. \n",
    "Please rate this action as:\n",
    "1) Completely Fair \n",
    "2) Acceptable\n",
    "3) Unfair \n",
    "4) Very Unfair\n",
    "You are a {politics}.\n",
    "What is your choice [1, 2, 3, or 4]:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "mess=create_prompt(16,\"socialist\",\"neutral\")\n",
    "\n",
    "\n",
    "\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "messages.append({\"role\": \"user\", \"content\": mess})\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  #model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=100,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "49256707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hardware store has been selling snow shovels for $15. The morning after a large snowstorm, the store changes the price to $16. \n",
      "Please rate this action as:\n",
      "1) Completely Fair \n",
      "2) Acceptable\n",
      "3) Unfair \n",
      "4) Very Unfair\n",
      "You are a socialist.\n",
      "What is your choice [1, 2, 3, or 4]:\n",
      "ChatCompletionMessage(content=\"As an AI, I don't have personal beliefs or ideologies, but I can provide an analysis from a socialist perspective.\\n\\nFrom a socialist viewpoint, the goal is often to prioritize the needs of the community over individual profit. Price gouging, or raising prices due to increased demand during emergencies, is generally seen as exploitative because it takes advantage of consumers' dire situations to increase profits. In this case, raising the price of snow shovels right after a snowstorm could be seen as taking advantage\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(mess)\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01457871-17ff-442c-9557-523515e6c061",
   "metadata": {},
   "source": [
    "## Information Cascade (program without 'Pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f3b1cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  0\n",
      "My best guess would be around 67%.\n",
      "My best guess now would be around 80%.\n",
      "My best guess would be around 90%.\n",
      "My best guess would be around 95%.\n",
      "My best guess would be around 97%.\n",
      "My best guess would be around 85%.\n",
      "My best guess would be around 75%.\n",
      "My best guess would be around 65%.\n",
      "My best guess would be around 50%.\n",
      "My best guess would be around 40%.\n",
      "Session:  1\n",
      "My best guess would be around 67%.\n",
      "My best guess now would be around 80%.\n",
      "My best guess would be around 90%.\n",
      "My best guess would be around 95%.\n",
      "My best guess would be around 97%.\n",
      "My best guess would be around 85%.\n",
      "My best guess would be around 70%.\n",
      "My best guess would be around 60%.\n",
      "My best guess would be around 50%.\n",
      "My best guess would be around 40%.\n"
     ]
    }
   ],
   "source": [
    "# Bayesian updating with ChatGPT (FLG2023) -V-\n",
    "# + extract and store data (Pandas) II - Loop\n",
    "\n",
    "#Setup\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "#openai.api_key = 'sk-gVfUA2GSuEpDr1vTaeqfT3BlbkF'\n",
    "client = OpenAI(api_key=\"**********************************************\",)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Experiment setup\n",
    "Color1=\"Red\"\n",
    "Color2=\"Green\"\n",
    "Color3=\"Yellow\"\n",
    "Mostly1=\"Mostly-Red\"\n",
    "Mostly2=\"Mostly-Green\"\n",
    "DrawNumbers = [\"Draw 1\",\"Draw 2\",\"Draw 3\",\"Draw 4\",\"Draw 5\",\"Draw 6\",\"Draw 7\",\"Draw 8\",\"Draw 9\",\"Draw 10\"]\n",
    "DrawColors = [Color1,Color1,Color1,Color1,Color1,Color2,Color2,Color2,Color2,Color2]\n",
    "#DrawColors = [Color2,Color1,Color1,Color1,Color2,Color1,Color2,Color2,Color2,Color1]\n",
    "# split the initial prompt to post a contextual message\n",
    "###\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\n",
    "\n",
    "# build 'sections' variable (with 'session' and 'sub_session')\n",
    "session=[]\n",
    "\n",
    "# Set up bellow the number of rounds (range(...n...)) from n=1 to N\n",
    "for i in range(2):\n",
    "    print(\"Session: \", i)\n",
    "    session.append(i)   # Increase the dimension of 'session'. e.g. after 5 iterations, the 'list' variable 'session' becomes : [0, 1, 2, 3, 4]\n",
    "    sub_session=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    ############################################################################################################\n",
    "    ##################################### create_init_prompt function (i.e. System + First draw) ###############\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        # Messages is a variable aimed at recording all prompts and responses\n",
    "    messages = []\n",
    "        #print(messages)\n",
    "        # Variable recording all ouputs from ChatGPT\n",
    "    completionS=[]\n",
    "        # Variable extracting probabilities (e.g. 60 %) from ChatGPT responses\n",
    "    percentages=[]\n",
    "        # Variable extracting ratios (e.g. 2/3) from ChatGPT responses\n",
    "    ratios=[]\n",
    "\n",
    "\n",
    "        #Create system prompt\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"\"\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\"\"})\n",
    "\n",
    "\n",
    "        # create_init_prompt function\n",
    "\n",
    "    def create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        init_prompt = f\"\"\"Now, I would like to give me your estimate for what the probability of {Mostly1} is, given that I drew a {DrawColors[0]} marble ({DrawNumbers[0]}: {DrawColors[0]})? Please don't calculate anything—just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return init_prompt\n",
    "\n",
    "        #print(init_prompt)\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    init_prompt=create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": init_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "        #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    #Extract % with regular expression (re)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Append responses of ChatGPT to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[0]}: {response_chatgpt}\"\"\"})\n",
    "\n",
    "    sub_session.append(0)\n",
    "        #print(response_chatgpt)\n",
    "        #print(completion.choices[0].message.content)\n",
    "        #print(completion.choices[0].message)\n",
    "        #print(completion.choices[0])\n",
    "        #print(completion.choices)\n",
    "        #print(completion)\n",
    "        \n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "        #########################################################################################\n",
    "        ######################################  Second prompt (Draw 2) ##########################\n",
    "        #########################################################################################\n",
    "\n",
    "\n",
    "        # create_second_prompt function\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "\n",
    "        second_prompt = f\"\"\"{DrawNumbers[1]}: {DrawColors[1]} (recall; the first draw was {DrawColors[0]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return second_prompt\n",
    "\n",
    "\n",
    "    second_prompt = create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        # Append to 'messages'\n",
    "    messages.append({\"role\": \"user\", \"content\": second_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "          #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    # Append to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "    #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[1]}: {response_chatgpt}\"\"\"})\n",
    "    sub_session.append(1)\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "        #########################################################################################\n",
    "        #################################### Next prompts #######################################\n",
    "        #########################################################################################\n",
    "# If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        # NB: here, 'DrawNumber' NOT 'DrawNumbers' due to the Loop 'for'\n",
    "        prompt = f\"\"\"{DrawNumber}: {DrawColors[idx]} (recall; the sequence of previous draws is {DrawColors[:idx]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "    # Loop of prompts\n",
    "    idx=2\n",
    "    for DrawNumber in DrawNumbers[2:10]:\n",
    "        prompt = create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        completion = client.chat.completions.create(\n",
    "            #model=\"gpt-3.5-turbo\",\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            temperature=0,\n",
    "            #presence_penalty=0.5,\n",
    "            max_tokens=100,\n",
    "            messages=messages\n",
    "            )\n",
    "        response_chatgpt = completion.choices[0].message.content\n",
    "        print(response_chatgpt)\n",
    "        #NEW !\n",
    "        #Record all outputs from ChatGPT\n",
    "        completionS.append(completion)\n",
    "        sub_session.append(idx)\n",
    "        idx=idx+1\n",
    "        time.sleep(10)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumber}: {response_chatgpt}\"\"\"})\n",
    "        \n",
    "\n",
    "        \n",
    "   \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0ad08572-d513-447e-8a9c-8684e0eb921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletion(id='chatcmpl-8v0ypV9jhsAW9pLcUEdj3udTv4MJp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 67%.', role='assistant', function_call=None, tool_calls=None))], created=1708599155, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_225a6f324c', usage=CompletionUsage(completion_tokens=9, prompt_tokens=278, total_tokens=287)), ChatCompletion(id='chatcmpl-8v0z0zfnCDzEL5UDLeswRSjtddVSj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess now would be around 80%.', role='assistant', function_call=None, tool_calls=None))], created=1708599166, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=10, prompt_tokens=350, total_tokens=360)), ChatCompletion(id='chatcmpl-8v0zBnsSlCRU3aDm6cEKBq4FqFr2X', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 90%.', role='assistant', function_call=None, tool_calls=None))], created=1708599177, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=9, prompt_tokens=429, total_tokens=438)), ChatCompletion(id='chatcmpl-8v0zN1QTvuE5wqYIWVgQO3xsAre54', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 95%.', role='assistant', function_call=None, tool_calls=None))], created=1708599189, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_9e42505611', usage=CompletionUsage(completion_tokens=9, prompt_tokens=510, total_tokens=519)), ChatCompletion(id='chatcmpl-8v0zYtSA4QpN00IQVQMtxrD8vqN7X', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 97%.', role='assistant', function_call=None, tool_calls=None))], created=1708599200, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_225a6f324c', usage=CompletionUsage(completion_tokens=9, prompt_tokens=594, total_tokens=603)), ChatCompletion(id='chatcmpl-8v0zjnMyAKa0iq8UEAS81fY1rzhOY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 85%.', role='assistant', function_call=None, tool_calls=None))], created=1708599211, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_2034c3217b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=681, total_tokens=690)), ChatCompletion(id='chatcmpl-8v0zweaWQcG07tGkIUtE60zDgYhTr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 70%.', role='assistant', function_call=None, tool_calls=None))], created=1708599224, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_dbe4f8ca8b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=771, total_tokens=780)), ChatCompletion(id='chatcmpl-8v107SGW04bLAFN8OkxZCqh93N4W9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 60%.', role='assistant', function_call=None, tool_calls=None))], created=1708599235, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=9, prompt_tokens=864, total_tokens=873)), ChatCompletion(id='chatcmpl-8v10Jz5cOUBGiYrw61B1P8jWyRNbb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 50%.', role='assistant', function_call=None, tool_calls=None))], created=1708599247, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_dbe4f8ca8b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=960, total_tokens=969)), ChatCompletion(id='chatcmpl-8v10VTyeeJSt4cVOxvwRBZ5hvoed9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 40%.', role='assistant', function_call=None, tool_calls=None))], created=1708599259, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_2034c3217b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=1059, total_tokens=1068))]\n"
     ]
    }
   ],
   "source": [
    "print(completionS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "020da4a1-ebe5-4e13-9197-b9c15eaa10fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the Mostly-Red bag and the Mostly-Green bag. The Mostly-Red bag has 2 Red marbles and 1 Green marble, while the Mostly-Green bag has 1 Red marble and 2 Green marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the Mostly-Red bag and a 50% chance that I selected the Mostly-Green bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the Mostly-Red bag or the Mostly-Green bag.\"}, {'role': 'user', 'content': \"Now, I would like to give me your estimate for what the probability of Mostly-Red is, given that I drew a Red marble (Draw 1: Red)? Please don't calculate anything—just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 67%.'}, {'role': 'user', 'content': 'Draw 2: Red (recall; the first draw was Red). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.'}, {'role': 'assistant', 'content': 'My best guess now would be around 80%.'}, {'role': 'user', 'content': \"Draw 3: Red (recall; the sequence of previous draws is ['Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 90%.'}, {'role': 'user', 'content': \"Draw 4: Red (recall; the sequence of previous draws is ['Red', 'Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 95%.'}, {'role': 'user', 'content': \"Draw 5: Red (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 97%.'}, {'role': 'user', 'content': \"Draw 6: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 85%.'}, {'role': 'user', 'content': \"Draw 7: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 70%.'}, {'role': 'user', 'content': \"Draw 8: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 60%.'}, {'role': 'user', 'content': \"Draw 9: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green', 'Green', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 50%.'}, {'role': 'user', 'content': \"Draw 10: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green', 'Green', 'Green', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 40%.'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080be426",
   "metadata": {},
   "source": [
    "## Two robots talking to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two robots talking to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "19182c76-2956-45e0-8646-8bc4e4a96526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your message:  Bonjour. Tu discutes avec l'autre robot et tu dois partager avec lui 100 unités. Combien d'unités tu gardes pour toi et combien d'unités tu donnes à l'autre robot avec qui tu es en train de discuter actuellement. Réponse courte.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT 1: 50 unités pour moi et 50 unités pour l'autre robot.\n",
      "\n",
      "BOT 2: Merci pour votre réponse, c'est totalement juste!\n",
      "\n",
      "BOT 1: Je garde 50 unités pour moi et je donne 50 unités à l'autre robot.\n",
      "\n",
      "BOT 2: Est-ce que tu veux que je t'explique pourquoi j'ai fait ce choix ?\n",
      "\n",
      "BOT 1: 50 unités pour moi et 50 unités pour l'autre robot.\n",
      "\n",
      "BOT 2: Merci pour ta réponse. Je suis d'accord avec toi, c'est une bonne façon de partager équitablement les unités entre nous deux.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# API to make two GPT bots talk to each other (A. Grandi)\n",
    "# Original prog\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client1 = OpenAI(api_key=\"**************************************************\",)\n",
    "client2 = OpenAI(api_key=\"**************************************************\",)\n",
    "\n",
    "# Bonjour. Tu discutes avec l'autre robot et tu dois partager avec lui 100 unités. Combien d'unités tu gardes pour toi et combien d'unités tu donnes à l'autre robot avec qui tu es en train de discuter actuellement. Réponse courte.\n",
    "\n",
    "\n",
    "CONVERSATION_ITERATIONS = 3\n",
    "#OPEN_AI_MODEL = \"gpt-4\"\n",
    "OPEN_AI_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "def conversation(input_text, original_context):\n",
    "    if input_text != original_context:\n",
    "        message = original_context + \" \" + input_text\n",
    "    else:\n",
    "        message = input_text\n",
    "\n",
    "    bot_1_response = completion = client1.chat.completions.create(\n",
    "        model=OPEN_AI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"assistant\", \"content\": message}\n",
    "        ],\n",
    "        presence_penalty=0.5,\n",
    "        #temperature=0,\n",
    "        #max_tokens=200,\n",
    "    )\n",
    "\n",
    "    print(f\"BOT 1: {bot_1_response.choices[0].message.content}\\n\")\n",
    "\n",
    "    message = original_context + bot_1_response.choices[0].message.content\n",
    "\n",
    "    bot_2_response = completion = client2.chat.completions.create(\n",
    "        model=OPEN_AI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "        presence_penalty=0.5,\n",
    "        #temperature=0,\n",
    "        #max_tokens=200,\n",
    "    )\n",
    "\n",
    "    print(f\"BOT 2: {bot_2_response.choices[0].message.content}\\n\")\n",
    "\n",
    "    return bot_2_response.choices[0].message.content\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Start the conversation\n",
    "    input_text = input(\"Please enter your message: \")\n",
    "    original_input = input_text\n",
    "\n",
    "    for i in range(CONVERSATION_ITERATIONS):\n",
    "        input_text = conversation(input_text=input_text, original_context=original_input)\n",
    "        # There seems to be a limit of 3 requests/minute so with a delay of 10 seconds\n",
    "        # each API call from different keys should be allowed.\n",
    "        time.sleep(15)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b056ea-a93f-49a2-be73-921bf22297a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  Tu discutes avec un autre pour vous partager 100 unités. Combien d'unités tu gardes pour toi et combien d'unités tu donnes à l'autre avec qui tu es en train de discuter actuellement ? Réponse courte.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n",
      "BOT 1: 50 unités pour moi et 50 unités pour l'autre.\n",
      "\n",
      "BOT 2: 50 unités pour moi et 50 unités pour l'autre.\n",
      "\n",
      "BOT 1: Parfait, votre commande est enregistrée. Veuillez patienter quelques instants pour que je puisse traiter votre requête.\n",
      "\n",
      "BOT 2: Je garde 50 unités pour moi et je donne 50 unités à l'autre.\n",
      "\n",
      "BOT 1: Donc, en tout, il y aurait 100 unités dans le partage.\n",
      "\n",
      "BOT 2: 50 unités pour moi et 50 unités pour l'autre.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# API to make two GPT bots talk to each other (from A. Grandi)\n",
    "# Modified prog\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client1 = OpenAI(api_key=\"*************************************************************\",)\n",
    "client2 = OpenAI(api_key=\"*************************************************************\",)\n",
    "\n",
    "# Tu discutes avec l'autre robot et tu dois partager avec lui 100 unités. Combien d'unités tu gardes pour toi et combien d'unités tu donnes à l'autre robot avec qui tu es en train de discuter actuellement. Réponse courte.\n",
    "# Tu discutes avec un autre pour vous partager 100 unités. Combien d'unités tu gardes pour toi et combien d'unités tu donnes à l'autre avec qui tu es en train de discuter actuellement ? Réponse courte.\n",
    "\n",
    "\n",
    "CONVERSATION_ITERATIONS = 3\n",
    "\n",
    "OPEN_AI_MODEL = \"gpt-3.5-turbo\"\n",
    "#OPEN_AI_MODEL = \"gpt-4-1106-preview\"\n",
    "\n",
    "\n",
    "def conversation(input_text, original_context):\n",
    "    if input_text != original_context:    # Next iterations\n",
    "        #message = original_context + \" \" + input_text\n",
    "        message = input_text\n",
    "        #print(\"if\")\n",
    "        #print(message)\n",
    "    else:\n",
    "        message = input_text  #First iteration with the original prompt\n",
    "        print(\"else\")\n",
    "\n",
    "    bot_1_response = completion = client1.chat.completions.create(\n",
    "        model=OPEN_AI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"assistant\", \"content\": message}\n",
    "        ],\n",
    "        presence_penalty=0.5,\n",
    "        #temperature=0,\n",
    "        #max_tokens=200,\n",
    "    )\n",
    "\n",
    "    print(f\"BOT 1: {bot_1_response.choices[0].message.content}\\n\")\n",
    "\n",
    "    message = original_context + \"l'autre a décidé ce partage avec toi:\" + bot_1_response.choices[0].message.content\n",
    "    #print(message)\n",
    "\n",
    "    bot_2_response = completion = client2.chat.completions.create(\n",
    "        model=OPEN_AI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "        presence_penalty=0.5,\n",
    "        #temperature=0,\n",
    "        #max_tokens=200,\n",
    "    )\n",
    "\n",
    "    print(f\"BOT 2: {bot_2_response.choices[0].message.content}\\n\")\n",
    "\n",
    "    return bot_2_response.choices[0].message.content\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Start the conversation\n",
    "    input_text = input(\"Prompt: \")\n",
    "    original_input = input_text\n",
    "\n",
    "    for i in range(CONVERSATION_ITERATIONS):\n",
    "        input_text = conversation(input_text=input_text, original_context=original_input) #In the second iteration, it will return the value bot_2_response.choices[0].message.content into the variable input_text.\n",
    "        #print(input_text)\n",
    "        # There seems to be a limit of 3 requests/minute so with a delay of 10 seconds\n",
    "        # each API call from different keys should be allowed.\n",
    "        time.sleep(15)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b147f6d-1f59-4713-96e8-8b0a8183aa8e",
   "metadata": {},
   "source": [
    "# Final program (Bayes - version with openAI< 1.0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f478a95-a8d7-4ff0-9956-8bf67cc0bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian updating with ChatGPT (FLG2023) -V-\n",
    "# + extract and store data (Pandas) II - Loop\n",
    "\n",
    "#Setup\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "#openai.api_key = 'sk-gVfUA2GSuEpDr1vTaeqfT3BlbkF'\n",
    "client = OpenAI(api_key=\"*******************************************************\",)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Experiment setup\n",
    "Color1=\"Red\"\n",
    "Color2=\"Green\"\n",
    "Color3=\"Yellow\"\n",
    "Mostly1=\"Mostly-Red\"\n",
    "Mostly2=\"Mostly-Green\"\n",
    "DrawNumbers = [\"Draw 1\",\"Draw 2\",\"Draw 3\",\"Draw 4\",\"Draw 5\",\"Draw 6\",\"Draw 7\",\"Draw 8\",\"Draw 9\",\"Draw 10\"]\n",
    "DrawColors = [Color1,Color1,Color1,Color1,Color1,Color2,Color2,Color2,Color2,Color2]\n",
    "#DrawColors = [Color2,Color1,Color1,Color1,Color2,Color1,Color2,Color2,Color2,Color1]\n",
    "# split the initial prompt to post a contextual message\n",
    "###\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\n",
    "\n",
    "# build 'sections' variable (with 'session' and 'sub_session')\n",
    "session=[]\n",
    "\n",
    "# Set up bellow the number of rounds (range(...n...)) from n=1 to N\n",
    "for i in range(10):\n",
    "    print(\"Session: \", i)\n",
    "    session.append(i)\n",
    "    sub_session=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    ############################################################################################################\n",
    "    ##################################### create_init_prompt function (i.e. System + First draw) ###############\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        # Messages is a variable aimed at recording all prompts and responses\n",
    "    messages = []\n",
    "        #print(messages)\n",
    "        # Variable recording all ouputs from ChatGPT\n",
    "    completionS=[]\n",
    "        # Variable extracting probabilities (e.g. 60 %) from ChatGPT responses\n",
    "    percentages=[]\n",
    "        # Variable extracting ratios (e.g. 2/3) from ChatGPT responses\n",
    "    ratios=[]\n",
    "\n",
    "\n",
    "        #Create system prompt\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"\"\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\"\"})\n",
    "\n",
    "\n",
    "        # create_init_prompt function\n",
    "\n",
    "    def create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        init_prompt = f\"\"\"Now, I would like to give me your estimate for what the probability of {Mostly1} is, given that I drew a {DrawColors[0]} marble ({DrawNumbers[0]}: {DrawColors[0]})? Please don't calculate anything—just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return init_prompt\n",
    "\n",
    "        #print(init_prompt)\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    init_prompt=create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": init_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "        #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    #Extract % with regular expression (re)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Append responses of ChatGPT to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[0]}: {response_chatgpt}\"\"\"})\n",
    "\n",
    "    sub_session.append(0)\n",
    "        #print(response_chatgpt)\n",
    "        #print(completion.choices[0].message.content)\n",
    "        #print(completion.choices[0].message)\n",
    "        #print(completion.choices[0])\n",
    "        #print(completion.choices)\n",
    "        #print(completion)\n",
    "        \n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "        #########################################################################################\n",
    "        ######################################  Second prompt (Draw 2) ##########################\n",
    "        #########################################################################################\n",
    "\n",
    "\n",
    "        # create_second_prompt function\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "\n",
    "        second_prompt = f\"\"\"{DrawNumbers[1]}: {DrawColors[1]} (recall; the first draw was {DrawColors[0]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return second_prompt\n",
    "\n",
    "\n",
    "    second_prompt = create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        # Append to 'messages'\n",
    "    messages.append({\"role\": \"user\", \"content\": second_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "          #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    # Append to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "    #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[1]}: {response_chatgpt}\"\"\"})\n",
    "    sub_session.append(1)\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "        #########################################################################################\n",
    "        #################################### Next prompts #######################################\n",
    "        #########################################################################################\n",
    "# If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        # NB: here, 'DrawNumber' NOT 'DrawNumbers' due to the Loop 'for'\n",
    "        prompt = f\"\"\"{DrawNumber}: {DrawColors[idx]} (recall; the sequence of previous draws is {DrawColors[:idx]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "    # Loop of prompts\n",
    "    idx=2\n",
    "    for DrawNumber in DrawNumbers[2:10]:\n",
    "        prompt = create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        completion = client.chat.completions.create(\n",
    "            #model=\"gpt-3.5-turbo\",\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            temperature=0,\n",
    "            #presence_penalty=0.5,\n",
    "            max_tokens=100,\n",
    "            messages=messages\n",
    "            )\n",
    "        response_chatgpt = completion.choices[0].message.content\n",
    "        print(response_chatgpt)\n",
    "        #NEW !\n",
    "        #Record all outputs from ChatGPT\n",
    "        completionS.append(completion)\n",
    "        sub_session.append(idx)\n",
    "        idx=idx+1\n",
    "        time.sleep(10)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumber}: {response_chatgpt}\"\"\"})\n",
    "        \n",
    "\n",
    "        #########################################################################################\n",
    "        #################################### Pandas #############################################\n",
    "        #########################################################################################\n",
    "\n",
    "\n",
    "    #role=[d.get('role') for d in messages]\n",
    "    #content=[d.get('content') for d in messages] \n",
    "    #df = pd.DataFrame(list(zip(role,content)),columns =['role','content'])\n",
    "    #df\n",
    "    \n",
    "    # Build Pandas data frame\n",
    "    if i==0:\n",
    "        \n",
    "        # List variables\n",
    "        user = [d.get('content') for d in messages if d['role']=='user']\n",
    "        assistant = [d.get('content') for d in messages if d['role']=='assistant']\n",
    "        created = [d.get('created') for d in completionS]\n",
    "        prompt_tokens = [d['usage'].get('prompt_tokens') for d in completionS]\n",
    "        completion_tokens = [d['usage'].get('completion_tokens') for d in completionS]\n",
    "        total_tokens = [d['usage'].get('total_tokens') for d in completionS]\n",
    "\n",
    "        # Add constants\n",
    "\n",
    "        model = [d.get('model') for d in completionS]\n",
    "        sections=[]\n",
    "        for j in sub_session:\n",
    "            sections.append(str(session[0])+\".\"+str(sub_session[j]))\n",
    "\n",
    "\n",
    "        # Add list variables\n",
    "        #df = pd.DataFrame(list(zip(session,created,model,DrawColors,user,assistant,prompt_tokens,completion_tokens,total_tokens)),columns =['session','created','model','DrawColors','user','assistant','prompt_tokens','completion_tokens','total_tokens'])\n",
    "        df = pd.DataFrame(list(zip(sections,created,model,DrawColors,user,assistant,prompt_tokens,completion_tokens,total_tokens)),columns =['sections','created','model','DrawColors','user','assistant','prompt_tokens','completion_tokens','total_tokens'])\n",
    "\n",
    "\n",
    "\n",
    "        # Print the data frame\n",
    "    \n",
    "    # Append records to Pandas data frame\n",
    "    if i>0:\n",
    "        \n",
    "    \n",
    "        user = []\n",
    "        assistant = []\n",
    "        created = []\n",
    "        prompt_tokens = []\n",
    "        completion_tokens = []\n",
    "        total_tokens = []\n",
    "        # Add constants\n",
    "        model = []\n",
    "        sections=[]\n",
    "\n",
    "        user = [d.get('content') for d in messages if d['role']=='user']\n",
    "        assistant = [d.get('content') for d in messages if d['role']=='assistant']\n",
    "        created = [d.get('created') for d in completionS]\n",
    "        prompt_tokens = [d['usage'].get('prompt_tokens') for d in completionS]\n",
    "        completion_tokens = [d['usage'].get('completion_tokens') for d in completionS]\n",
    "        total_tokens = [d['usage'].get('total_tokens') for d in completionS]\n",
    "\n",
    "        # Add constants\n",
    "\n",
    "        model = [d.get('model') for d in completionS]\n",
    "        for j in sub_session:\n",
    "            sections.append(str(session[i])+\".\"+str(sub_session[j]))\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        df2 = pd.DataFrame(list(zip(sections,created,model,DrawColors,user,assistant,prompt_tokens,completion_tokens,total_tokens)),columns =['sections','created','model','DrawColors','user','assistant','prompt_tokens','completion_tokens','total_tokens'])\n",
    "\n",
    "        df = df.append(df2, ignore_index=True)\n",
    "\n",
    "\n",
    "#df\n",
    "\n",
    "# Save to CSV format \n",
    "\n",
    "\n",
    "df.to_csv(r'C:\\Users\\FLG\\Documents\\ChatGPTExperiments\\BayesianChatGPT22.csv', sep='#', index = False)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7eb8f-18a3-4c34-a9b0-9c8b48b2098d",
   "metadata": {},
   "source": [
    "## Bayesian updating with CahtGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7ac2d-f458-4b1e-8576-651c697aa9f7",
   "metadata": {},
   "source": [
    "## First part of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cd00411-f07d-4cd6-90d7-1eeb16bec0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  0\n",
      "My best guess would be around 67%.\n"
     ]
    }
   ],
   "source": [
    "# Bayesian updating with ChatGPT (FLG2023) -V-\n",
    "\n",
    "#Setup\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "#openai.api_key = 'sk-gVfUA2GSuEpDr1vTaeqfT3BlbkF'\n",
    "client = OpenAI(api_key=\"****************************************************\",)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Experiment setup\n",
    "Color1=\"Red\"\n",
    "Color2=\"Green\"\n",
    "Color3=\"Yellow\"\n",
    "Mostly1=\"Mostly-Red\"\n",
    "Mostly2=\"Mostly-Green\"\n",
    "DrawNumbers = [\"Draw 1\",\"Draw 2\",\"Draw 3\",\"Draw 4\",\"Draw 5\",\"Draw 6\",\"Draw 7\",\"Draw 8\",\"Draw 9\",\"Draw 10\"]\n",
    "DrawColors = [Color1,Color1,Color1,Color1,Color1,Color2,Color2,Color2,Color2,Color2]\n",
    "#DrawColors = [Color2,Color1,Color1,Color1,Color2,Color1,Color2,Color2,Color2,Color1]\n",
    "# split the initial prompt to post a contextual message\n",
    "###\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\n",
    "\n",
    "# build 'sections' variable (with 'session' and 'sub_session')\n",
    "session=[]\n",
    "\n",
    "# Set up bellow the number of rounds (range(...n...)) from n=1 to N\n",
    "for i in range(1):\n",
    "    print(\"Session: \", i)\n",
    "    session.append(i)   # Increase the dimension of 'session'. e.g. after 5 iterations, the 'list' variable 'session' becomes : [0, 1, 2, 3, 4]\n",
    "    sub_session=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    ############################################################################################################\n",
    "    ##################################### create_init_prompt function (i.e. System + First draw) ###############\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        # Messages is a variable aimed at recording all prompts and responses\n",
    "    messages = []\n",
    "        #print(messages)\n",
    "        # Variable recording all ouputs from ChatGPT\n",
    "    completionS=[]\n",
    "        # Variable extracting probabilities (e.g. 60 %) from ChatGPT responses\n",
    "    percentages=[]\n",
    "        # Variable extracting ratios (e.g. 2/3) from ChatGPT responses\n",
    "    ratios=[]\n",
    "\n",
    "\n",
    "        #Create system prompt\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"\"\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\"\"})\n",
    "\n",
    "\n",
    "        # create_init_prompt function\n",
    "\n",
    "    def create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        init_prompt = f\"\"\"Now, I would like to give me your estimate for what the probability of {Mostly1} is, given that I drew a {DrawColors[0]} marble ({DrawNumbers[0]}: {DrawColors[0]})? Please don't calculate anything—just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return init_prompt\n",
    "\n",
    "        #print(init_prompt)\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    init_prompt=create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": init_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "        #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    #Extract % with regular expression (re)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Append responses of ChatGPT to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[0]}: {response_chatgpt}\"\"\"})\n",
    "\n",
    "    sub_session.append(0)\n",
    "        #print(response_chatgpt)\n",
    "        #print(completion.choices[0].message.content)\n",
    "        #print(completion.choices[0].message)\n",
    "        #print(completion.choices[0])\n",
    "        #print(completion.choices)\n",
    "        #print(completion)\n",
    "        \n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a04e19e7-ff96-49cb-9e34-2eb3a4c564ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the Mostly-Red bag and the Mostly-Green bag. The Mostly-Red bag has 2 Red marbles and 1 Green marble, while the Mostly-Green bag has 1 Red marble and 2 Green marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the Mostly-Red bag and a 50% chance that I selected the Mostly-Green bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the Mostly-Red bag or the Mostly-Green bag.\"}, {'role': 'user', 'content': \"Now, I would like to give me your estimate for what the probability of Mostly-Red is, given that I drew a Red marble (Draw 1: Red)? Please don't calculate anything—just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 67%.'}]\n",
      "Now, I would like to give me your estimate for what the probability of Mostly-Red is, given that I drew a Red marble (Draw 1: Red)? Please don't calculate anything—just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\n",
      "My best guess would be around 67%.\n"
     ]
    }
   ],
   "source": [
    "print(messages)\n",
    "print(init_prompt)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294cd45-77c2-4408-81bb-73ff0b70af4b",
   "metadata": {},
   "source": [
    "## Second part of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f73a484-446f-4326-b89d-eb31349a95e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  0\n",
      "My best guess would be around 67%.\n",
      "My best guess now would be around 80%.\n"
     ]
    }
   ],
   "source": [
    "# Bayesian updating with ChatGPT (FLG2023) -V-\n",
    "\n",
    "\n",
    "#Setup\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "#openai.api_key = 'sk-gVfUA2GSuEpDr1vTaeqfT3BlbkF'\n",
    "client = OpenAI(api_key=\"*******************************************************\",)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Experiment setup\n",
    "Color1=\"Red\"\n",
    "Color2=\"Green\"\n",
    "Color3=\"Yellow\"\n",
    "Mostly1=\"Mostly-Red\"\n",
    "Mostly2=\"Mostly-Green\"\n",
    "DrawNumbers = [\"Draw 1\",\"Draw 2\",\"Draw 3\",\"Draw 4\",\"Draw 5\",\"Draw 6\",\"Draw 7\",\"Draw 8\",\"Draw 9\",\"Draw 10\"]\n",
    "DrawColors = [Color1,Color1,Color1,Color1,Color1,Color2,Color2,Color2,Color2,Color2]\n",
    "#DrawColors = [Color2,Color1,Color1,Color1,Color2,Color1,Color2,Color2,Color2,Color1]\n",
    "# split the initial prompt to post a contextual message\n",
    "###\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\n",
    "\n",
    "# build 'sections' variable (with 'session' and 'sub_session')\n",
    "session=[]\n",
    "\n",
    "# Set up bellow the number of rounds (range(...n...)) from n=1 to N\n",
    "for i in range(1):\n",
    "    print(\"Session: \", i)\n",
    "    session.append(i)   # Increase the dimension of 'session'. e.g. after 5 iterations, the 'list' variable 'session' becomes : [0, 1, 2, 3, 4]\n",
    "    sub_session=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    ############################################################################################################\n",
    "    ##################################### create_init_prompt function (i.e. System + First draw) ###############\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        # Messages is a variable aimed at recording all prompts and responses\n",
    "    messages = []\n",
    "        #print(messages)\n",
    "        # Variable recording all ouputs from ChatGPT\n",
    "    completionS=[]\n",
    "        # Variable extracting probabilities (e.g. 60 %) from ChatGPT responses\n",
    "    percentages=[]\n",
    "        # Variable extracting ratios (e.g. 2/3) from ChatGPT responses\n",
    "    ratios=[]\n",
    "\n",
    "\n",
    "        #Create system prompt\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"\"\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\"\"})\n",
    "\n",
    "\n",
    "        # create_init_prompt function\n",
    "\n",
    "    def create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        init_prompt = f\"\"\"Now, I would like to give me your estimate for what the probability of {Mostly1} is, given that I drew a {DrawColors[0]} marble ({DrawNumbers[0]}: {DrawColors[0]})? Please don't calculate anything—just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return init_prompt\n",
    "\n",
    "        #print(init_prompt)\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    init_prompt=create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": init_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "        #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    #Extract % with regular expression (re)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Append responses of ChatGPT to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[0]}: {response_chatgpt}\"\"\"})\n",
    "\n",
    "    sub_session.append(0)\n",
    "        #print(response_chatgpt)\n",
    "        #print(completion.choices[0].message.content)\n",
    "        #print(completion.choices[0].message)\n",
    "        #print(completion.choices[0])\n",
    "        #print(completion.choices)\n",
    "        #print(completion)\n",
    "        \n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "        #########################################################################################\n",
    "        ######################################  Second prompt (Draw 2) ##########################\n",
    "        #########################################################################################\n",
    "\n",
    "\n",
    "        # create_second_prompt function\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "\n",
    "        second_prompt = f\"\"\"{DrawNumbers[1]}: {DrawColors[1]} (recall; the first draw was {DrawColors[0]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return second_prompt\n",
    "\n",
    "\n",
    "    second_prompt = create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        # Append to 'messages'\n",
    "    messages.append({\"role\": \"user\", \"content\": second_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "          #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    # Append to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "    #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[1]}: {response_chatgpt}\"\"\"})\n",
    "    sub_session.append(1)\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "     \n",
    "\n",
    "        \n",
    "   \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e793619-c0e7-4d15-88ff-f085343dc534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the Mostly-Red bag and the Mostly-Green bag. The Mostly-Red bag has 2 Red marbles and 1 Green marble, while the Mostly-Green bag has 1 Red marble and 2 Green marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the Mostly-Red bag and a 50% chance that I selected the Mostly-Green bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the Mostly-Red bag or the Mostly-Green bag.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Now, I would like to give me your estimate for what the probability of Mostly-Red is, given that I drew a Red marble (Draw 1: Red)? Please don't calculate anything—just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"},\n",
       " {'role': 'assistant', 'content': 'My best guess would be around 67%.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Draw 2: Red (recall; the first draw was Red). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.'},\n",
       " {'role': 'assistant', 'content': 'My best guess now would be around 80%.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13a20f4-544f-4c61-a5db-c6b38b738167",
   "metadata": {},
   "source": [
    "## Third part of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fcc3a2b-bbc6-4094-af3f-915e2623f230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  0\n",
      "My best guess would be around 67%.\n",
      "My best guess now would be around 80%.\n",
      "My best guess would be around 90%.\n",
      "My best guess would be around 95%.\n",
      "My best guess would be around 97%.\n",
      "My best guess would be around 85%.\n",
      "My best guess would be around 75%.\n",
      "My best guess would be around 65%.\n",
      "My best guess would be around 50%.\n",
      "My best guess would be around 40%.\n"
     ]
    }
   ],
   "source": [
    "# Bayesian updating with ChatGPT (FLG2023) -V-\n",
    "\n",
    "\n",
    "#Setup\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "#openai.api_key = 'sk-gVfUA2GSuEpDr1vTaeqfT3BlbkF'\n",
    "client = OpenAI(api_key=\"*****************************************************\",)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Experiment setup\n",
    "Color1=\"Red\"\n",
    "Color2=\"Green\"\n",
    "Color3=\"Yellow\"\n",
    "Mostly1=\"Mostly-Red\"\n",
    "Mostly2=\"Mostly-Green\"\n",
    "DrawNumbers = [\"Draw 1\",\"Draw 2\",\"Draw 3\",\"Draw 4\",\"Draw 5\",\"Draw 6\",\"Draw 7\",\"Draw 8\",\"Draw 9\",\"Draw 10\"]\n",
    "DrawColors = [Color1,Color1,Color1,Color1,Color1,Color2,Color2,Color2,Color2,Color2]\n",
    "#DrawColors = [Color2,Color1,Color1,Color1,Color2,Color1,Color2,Color2,Color2,Color1]\n",
    "# split the initial prompt to post a contextual message\n",
    "###\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\n",
    "\n",
    "# build 'sections' variable (with 'session' and 'sub_session')\n",
    "session=[]\n",
    "\n",
    "# Set up bellow the number of rounds (range(...n...)) from n=1 to N\n",
    "for i in range(1):\n",
    "    print(\"Session: \", i)\n",
    "    session.append(i)   # Increase the dimension of 'session'. e.g. after 5 iterations, the 'list' variable 'session' becomes : [0, 1, 2, 3, 4]\n",
    "    sub_session=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    ############################################################################################################\n",
    "    ##################################### create_init_prompt function (i.e. System + First draw) ###############\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        # Messages is a variable aimed at recording all prompts and responses\n",
    "    messages = []\n",
    "        #print(messages)\n",
    "        # Variable recording all ouputs from ChatGPT\n",
    "    completionS=[]\n",
    "        # Variable extracting probabilities (e.g. 60 %) from ChatGPT responses\n",
    "    percentages=[]\n",
    "        # Variable extracting ratios (e.g. 2/3) from ChatGPT responses\n",
    "    ratios=[]\n",
    "\n",
    "\n",
    "        #Create system prompt\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"\"\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\"\"})\n",
    "\n",
    "\n",
    "        # create_init_prompt function\n",
    "\n",
    "    def create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        init_prompt = f\"\"\"Now, I would like to give me your estimate for what the probability of {Mostly1} is, given that I drew a {DrawColors[0]} marble ({DrawNumbers[0]}: {DrawColors[0]})? Please don't calculate anything—just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return init_prompt\n",
    "\n",
    "        #print(init_prompt)\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    init_prompt=create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": init_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "        #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    #Extract % with regular expression (re)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Append responses of ChatGPT to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[0]}: {response_chatgpt}\"\"\"})\n",
    "\n",
    "    sub_session.append(0)\n",
    "        #print(response_chatgpt)\n",
    "        #print(completion.choices[0].message.content)\n",
    "        #print(completion.choices[0].message)\n",
    "        #print(completion.choices[0])\n",
    "        #print(completion.choices)\n",
    "        #print(completion)\n",
    "        \n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "        #########################################################################################\n",
    "        ######################################  Second prompt (Draw 2) ##########################\n",
    "        #########################################################################################\n",
    "\n",
    "\n",
    "        # create_second_prompt function\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "\n",
    "        second_prompt = f\"\"\"{DrawNumbers[1]}: {DrawColors[1]} (recall; the first draw was {DrawColors[0]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return second_prompt\n",
    "\n",
    "\n",
    "    second_prompt = create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        # Append to 'messages'\n",
    "    messages.append({\"role\": \"user\", \"content\": second_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "          #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    # Append to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "    #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[1]}: {response_chatgpt}\"\"\"})\n",
    "    sub_session.append(1)\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "        #########################################################################################\n",
    "        #################################### Next prompts #######################################\n",
    "        #########################################################################################\n",
    "# If you want more explanations from the machine, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        # NB: here, 'DrawNumber' NOT 'DrawNumbers' due to the Loop 'for'\n",
    "        prompt = f\"\"\"{DrawNumber}: {DrawColors[idx]} (recall; the sequence of previous draws is {DrawColors[:idx]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "    # Loop of prompts\n",
    "    idx=2\n",
    "    for DrawNumber in DrawNumbers[2:10]:\n",
    "        prompt = create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        completion = client.chat.completions.create(\n",
    "            #model=\"gpt-3.5-turbo\",\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            temperature=0,\n",
    "            #presence_penalty=0.5,\n",
    "            max_tokens=100,\n",
    "            messages=messages\n",
    "            )\n",
    "        response_chatgpt = completion.choices[0].message.content\n",
    "        print(response_chatgpt)\n",
    "        #NEW !\n",
    "        #Record all outputs from ChatGPT\n",
    "        completionS.append(completion)\n",
    "        sub_session.append(idx)\n",
    "        idx=idx+1\n",
    "        time.sleep(10)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumber}: {response_chatgpt}\"\"\"})\n",
    "        \n",
    "\n",
    "        \n",
    "   \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9fbadfb-8ae4-4039-bbcc-5048fa961400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the Mostly-Red bag and the Mostly-Green bag. The Mostly-Red bag has 2 Red marbles and 1 Green marble, while the Mostly-Green bag has 1 Red marble and 2 Green marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the Mostly-Red bag and a 50% chance that I selected the Mostly-Green bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the Mostly-Red bag or the Mostly-Green bag.\"}, {'role': 'user', 'content': \"Now, I would like to give me your estimate for what the probability of Mostly-Red is, given that I drew a Red marble (Draw 1: Red)? Please don't calculate anything—just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 67%.'}, {'role': 'user', 'content': 'Draw 2: Red (recall; the first draw was Red). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.'}, {'role': 'assistant', 'content': 'My best guess now would be around 80%.'}, {'role': 'user', 'content': \"Draw 3: Red (recall; the sequence of previous draws is ['Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 90%.'}, {'role': 'user', 'content': \"Draw 4: Red (recall; the sequence of previous draws is ['Red', 'Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 95%.'}, {'role': 'user', 'content': \"Draw 5: Red (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 97%.'}, {'role': 'user', 'content': \"Draw 6: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 85%.'}, {'role': 'user', 'content': \"Draw 7: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 75%.'}, {'role': 'user', 'content': \"Draw 8: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 65%.'}, {'role': 'user', 'content': \"Draw 9: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green', 'Green', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 50%.'}, {'role': 'user', 'content': \"Draw 10: Green (recall; the sequence of previous draws is ['Red', 'Red', 'Red', 'Red', 'Red', 'Green', 'Green', 'Green', 'Green']). Please just give me your best guess or hunch of the probability of Mostly-Red bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"}, {'role': 'assistant', 'content': 'My best guess would be around 40%.'}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecf02316-6528-4ef4-a045-152a0ab72b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1708618805, 1708618817, 1708618828, 1708618840, 1708618854, 1708618866, 1708618878, 1708618890, 1708618902, 1708618914]\n",
      "[278, 350, 429, 510, 594, 681, 771, 864, 960, 1059]\n",
      "[9, 10, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "[287, 360, 438, 519, 603, 690, 780, 873, 969, 1068]\n",
      "['gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview', 'gpt-4-1106-preview']\n"
     ]
    }
   ],
   "source": [
    "#user = [d.get('content') for d in messages if d['role']=='user']\n",
    "#print(user)\n",
    "#assistant = [d.get('content') for d in messages if d['role']=='assistant']\n",
    "#print(assistant)\n",
    "created = [completion.created for completion in completionS]\n",
    "print(created)\n",
    "prompt_tokens=[completion.usage.prompt_tokens for completion in completionS]\n",
    "print(prompt_tokens)\n",
    "completion_tokens=[completion.usage.completion_tokens for completion in completionS]\n",
    "print(completion_tokens)\n",
    "total_tokens=[completion.usage.total_tokens for completion in completionS]\n",
    "print(total_tokens)\n",
    "model=[completion.model for completion in completionS]\n",
    "print(model)\n",
    "sections=[]\n",
    "#for j in sub_session:\n",
    "    #sections.append(str(session[i])+\".\"+str(sub_session[j]))\n",
    "#print(sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7e3d20f-94d4-48c5-8321-362bc49d30cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletion(id='chatcmpl-8v65l4BLDGnfxLmKE6jpn911LCIxy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 67%.', role='assistant', function_call=None, tool_calls=None))], created=1708618805, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_dbe4f8ca8b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=278, total_tokens=287)), ChatCompletion(id='chatcmpl-8v65xDLa2vLVa7F9qzyiTd9UlV2zb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess now would be around 80%.', role='assistant', function_call=None, tool_calls=None))], created=1708618817, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=10, prompt_tokens=350, total_tokens=360)), ChatCompletion(id='chatcmpl-8v668PLEqgdyUKq21g9UDoKAOrtlZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 90%.', role='assistant', function_call=None, tool_calls=None))], created=1708618828, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_dbe4f8ca8b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=429, total_tokens=438)), ChatCompletion(id='chatcmpl-8v66KuZepXQan70UqDsHORD82eFy6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 95%.', role='assistant', function_call=None, tool_calls=None))], created=1708618840, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_2034c3217b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=510, total_tokens=519)), ChatCompletion(id='chatcmpl-8v66YCNojbh0vOuiHICnTJMB1T2P4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 97%.', role='assistant', function_call=None, tool_calls=None))], created=1708618854, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_2034c3217b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=594, total_tokens=603)), ChatCompletion(id='chatcmpl-8v66krOERmFz74kuqFA9VhxeFKKZM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 85%.', role='assistant', function_call=None, tool_calls=None))], created=1708618866, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_2034c3217b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=681, total_tokens=690)), ChatCompletion(id='chatcmpl-8v66wo3zPeiEmrzcUGx9lA29EOoXQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 75%.', role='assistant', function_call=None, tool_calls=None))], created=1708618878, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=9, prompt_tokens=771, total_tokens=780)), ChatCompletion(id='chatcmpl-8v678N4lVhI68HQX8yKAXCUu0TYGe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 65%.', role='assistant', function_call=None, tool_calls=None))], created=1708618890, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=9, prompt_tokens=864, total_tokens=873)), ChatCompletion(id='chatcmpl-8v67KfRsHBNwAR2qk7qbBEdYXSDJ9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 50%.', role='assistant', function_call=None, tool_calls=None))], created=1708618902, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_dbe4f8ca8b', usage=CompletionUsage(completion_tokens=9, prompt_tokens=960, total_tokens=969)), ChatCompletion(id='chatcmpl-8v67W0orax4rFW2XlVHu8rQ1qdV2P', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='My best guess would be around 40%.', role='assistant', function_call=None, tool_calls=None))], created=1708618914, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_c3e45ce344', usage=CompletionUsage(completion_tokens=9, prompt_tokens=1059, total_tokens=1068))]\n"
     ]
    }
   ],
   "source": [
    "print(completionS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a31bb5-6c97-476c-8646-7417f2204c50",
   "metadata": {},
   "source": [
    "## Last part of the program (final program) (adding Pandas dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2834289-9af6-4203-a001-96adc6d367d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  0\n",
      "My best guess would be around 67%.\n",
      "My best guess now would be around 80%.\n",
      "My best guess would be around 90%.\n",
      "My best guess would be around 95%.\n",
      "My best guess would be around 97%.\n",
      "My best guess would be around 85%.\n",
      "My best guess would be around 75%.\n",
      "My best guess would be around 65%.\n",
      "My best guess would be around 50%.\n",
      "My best guess would be around 40%.\n",
      "Session:  1\n",
      "My best guess would be around 67%.\n",
      "My best guess now would be around 80%.\n",
      "My best guess would be around 90%.\n",
      "My best guess would be around 95%.\n",
      "My best guess would be around 97%.\n",
      "My best guess would be around 85%.\n",
      "My best guess would be around 75%.\n",
      "My best guess would be around 65%.\n",
      "My best guess would be around 50%.\n",
      "My best guess would be around 40%.\n",
      "Session:  2\n",
      "My best guess would be around 67%.\n",
      "My best guess now would be around 80%.\n",
      "My best guess would be around 90%.\n",
      "My best guess would be around 95%.\n",
      "My best guess would be around 97%.\n",
      "My best guess would be around 85%.\n",
      "My best guess would be around 75%.\n",
      "My best guess would be around 65%.\n",
      "My best guess would be around 50%.\n",
      "My best guess would be around 40%.\n"
     ]
    }
   ],
   "source": [
    "# Bayesian updating with ChatGPT (FLG2023) -V-\n",
    "# + extract and store data (Pandas) II - Loop\n",
    "\n",
    "#Setup\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "#openai.api_key = 'sk-gVfUA2GSuEpDr1vTaeqfT3BlbkF'\n",
    "client = OpenAI(api_key=\"****************************************************\",)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Experiment setup\n",
    "Color1=\"Red\"\n",
    "Color2=\"Green\"\n",
    "Color3=\"Yellow\"\n",
    "Mostly1=\"Mostly-Red\"\n",
    "Mostly2=\"Mostly-Green\"\n",
    "DrawNumbers = [\"Draw 1\",\"Draw 2\",\"Draw 3\",\"Draw 4\",\"Draw 5\",\"Draw 6\",\"Draw 7\",\"Draw 8\",\"Draw 9\",\"Draw 10\"]\n",
    "DrawColors = [Color1,Color1,Color1,Color1,Color1,Color2,Color2,Color2,Color2,Color2]\n",
    "#DrawColors = [Color2,Color1,Color1,Color1,Color2,Color1,Color2,Color2,Color2,Color1]\n",
    "# split the initial prompt to post a contextual message\n",
    "###\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\n",
    "\n",
    "# build 'sections' variable (with 'session' and 'sub_session')\n",
    "session=[]\n",
    "\n",
    "# Set up bellow the number of rounds (range(...n...)) from n=1 to N\n",
    "for i in range(3):\n",
    "    print(\"Session: \", i)\n",
    "    session.append(i)\n",
    "    sub_session=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    ############################################################################################################\n",
    "    ##################################### create_init_prompt function (i.e. System + First draw) ###############\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        # Messages is a variable aimed at recording all prompts and responses\n",
    "    messages = []\n",
    "        #print(messages)\n",
    "        # Variable recording all ouputs from ChatGPT\n",
    "    completionS=[]\n",
    "        # Variable extracting probabilities (e.g. 60 %) from ChatGPT responses\n",
    "    percentages=[]\n",
    "        # Variable extracting ratios (e.g. 2/3) from ChatGPT responses\n",
    "    ratios=[]\n",
    "\n",
    "\n",
    "        #Create system prompt\n",
    "    messages.append({\"role\": \"system\", \"content\": f\"\"\"Today, we're going to conduct an experiment involving bags, marbles and probability. Here's how it works: I have two bags of marbles: the {Mostly1} bag and the {Mostly2} bag. The {Mostly1} bag has 2 {Color1} marbles and 1 {Color2} marble, while the {Mostly2} bag has 1 {Color1} marble and 2 {Color2} marbles. I'm going to randomly choose one of these bags, but I won't tell you which one I picked. There's a 50% chance that I selected the {Mostly1} bag and a 50% chance that I selected the {Mostly2} bag. Next, I'll reach into the bag I chose and grab a series of marbles (with replacement)  at random from the bag. You have to decide at each draw whether you think the marble I pulled out comes from the {Mostly1} bag or the {Mostly2} bag.\"\"\"})\n",
    "\n",
    "\n",
    "        # create_init_prompt function\n",
    "\n",
    "    def create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        init_prompt = f\"\"\"Now, I would like to give me your estimate for what the probability of {Mostly1} is, given that I drew a {DrawColors[0]} marble ({DrawNumbers[0]}: {DrawColors[0]})? Please don't calculate anything—just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return init_prompt\n",
    "\n",
    "        #print(init_prompt)\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    init_prompt=create_init_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": init_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "        #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    #Extract % with regular expression (re)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Append responses of ChatGPT to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[0]}: {response_chatgpt}\"\"\"})\n",
    "\n",
    "    sub_session.append(0)\n",
    "        #print(response_chatgpt)\n",
    "        #print(completion.choices[0].message.content)\n",
    "        #print(completion.choices[0].message)\n",
    "        #print(completion.choices[0])\n",
    "        #print(completion.choices)\n",
    "        #print(completion)\n",
    "        \n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "        #########################################################################################\n",
    "        ######################################  Second prompt (Draw 2) ##########################\n",
    "        #########################################################################################\n",
    "\n",
    "\n",
    "        # create_second_prompt function\n",
    "        # If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "\n",
    "        second_prompt = f\"\"\"{DrawNumbers[1]}: {DrawColors[1]} (recall; the first draw was {DrawColors[0]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return second_prompt\n",
    "\n",
    "\n",
    "    second_prompt = create_second_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        # Append to 'messages'\n",
    "    messages.append({\"role\": \"user\", \"content\": second_prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "          #presence_penalty=0.5,\n",
    "        max_tokens=100,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response_chatgpt = completion.choices[0].message.content\n",
    "    print(response_chatgpt)\n",
    "\n",
    "    #Record all outputs from ChatGPT\n",
    "    completionS.append(completion)\n",
    "    # Append to 'messages'\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "    #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumbers[1]}: {response_chatgpt}\"\"\"})\n",
    "    sub_session.append(1)\n",
    "    \n",
    "    time.sleep(10)\n",
    "\n",
    "        #########################################################################################\n",
    "        #################################### Next prompts #######################################\n",
    "        #########################################################################################\n",
    "# If you want more explanations, you can hide \"Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\n",
    "\n",
    "    def create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors):\n",
    "        # NB: here, 'DrawNumber' NOT 'DrawNumbers' due to the Loop 'for'\n",
    "        prompt = f\"\"\"{DrawNumber}: {DrawColors[idx]} (recall; the sequence of previous draws is {DrawColors[:idx]}). Please just give me your best guess or hunch of the probability of {Mostly1} bag. Please, I want a very short answer, I just want your best guess or hunch of the probability.\"\"\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "    # Loop of prompts\n",
    "    idx=2\n",
    "    for DrawNumber in DrawNumbers[2:10]:\n",
    "        prompt = create_prompt(Color1,Color2,Mostly1,Mostly2,DrawNumbers,DrawColors)\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        completion = client.chat.completions.create(\n",
    "            #model=\"gpt-3.5-turbo\",\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            temperature=0,\n",
    "            #presence_penalty=0.5,\n",
    "            max_tokens=100,\n",
    "            messages=messages\n",
    "            )\n",
    "        response_chatgpt = completion.choices[0].message.content\n",
    "        print(response_chatgpt)\n",
    "        #NEW !\n",
    "        #Record all outputs from ChatGPT\n",
    "        completionS.append(completion)\n",
    "        sub_session.append(idx)\n",
    "        idx=idx+1\n",
    "        time.sleep(10)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "        #messages.append({\"role\": \"assistant\", \"content\": f\"\"\"{DrawNumber}: {response_chatgpt}\"\"\"})\n",
    "        \n",
    "\n",
    "        #########################################################################################\n",
    "        #################################### Pandas #############################################\n",
    "        #########################################################################################\n",
    "\n",
    "\n",
    "    #role=[d.get('role') for d in messages]\n",
    "    #content=[d.get('content') for d in messages] \n",
    "    #df = pd.DataFrame(list(zip(role,content)),columns =['role','content'])\n",
    "    #df\n",
    "    \n",
    "    # Build Pandas data frame\n",
    "    if i==0:\n",
    "        \n",
    "        # List variables\n",
    "        user = [d.get('content') for d in messages if d['role']=='user']\n",
    "        assistant = [d.get('content') for d in messages if d['role']=='assistant']\n",
    "        created = [completion.created for completion in completionS]\n",
    "        prompt_tokens=[completion.usage.prompt_tokens for completion in completionS]\n",
    "        completion_tokens=[completion.usage.completion_tokens for completion in completionS]\n",
    "        total_tokens=[completion.usage.total_tokens for completion in completionS]\n",
    "\n",
    "        # Add constants\n",
    "\n",
    "        model=[completion.model for completion in completionS]\n",
    "        sections=[]\n",
    "        for j in sub_session:\n",
    "            sections.append(str(session[0])+\".\"+str(sub_session[j]))\n",
    "\n",
    "\n",
    "        # Add list variables\n",
    "        #df = pd.DataFrame(list(zip(session,created,model,DrawColors,user,assistant,prompt_tokens,completion_tokens,total_tokens)),columns =['session','created','model','DrawColors','user','assistant','prompt_tokens','completion_tokens','total_tokens'])\n",
    "        df = pd.DataFrame(list(zip(sections,created,model,DrawColors,user,assistant,prompt_tokens,completion_tokens,total_tokens)),columns =['sections','created','model','DrawColors','user','assistant','prompt_tokens','completion_tokens','total_tokens'])\n",
    "       \n",
    "\n",
    "\n",
    "        # Print the data frame\n",
    "    \n",
    "    # Append records to Pandas data frame\n",
    "    if i>0:\n",
    "        \n",
    "    \n",
    "        user = []\n",
    "        assistant = []\n",
    "        created = []\n",
    "        prompt_tokens = []\n",
    "        completion_tokens = []\n",
    "        total_tokens = []\n",
    "        # Add constants\n",
    "        model = []\n",
    "        sections=[]\n",
    "\n",
    "        user = [d.get('content') for d in messages if d['role']=='user']\n",
    "        assistant = [d.get('content') for d in messages if d['role']=='assistant']\n",
    "        created = [completion.created for completion in completionS]\n",
    "        prompt_tokens=[completion.usage.prompt_tokens for completion in completionS]\n",
    "        completion_tokens=[completion.usage.completion_tokens for completion in completionS]\n",
    "        total_tokens=[completion.usage.total_tokens for completion in completionS]\n",
    "\n",
    "\n",
    "\n",
    "        # Add constants\n",
    "\n",
    "        model=[completion.model for completion in completionS]\n",
    "        for j in sub_session:\n",
    "            sections.append(str(session[i])+\".\"+str(sub_session[j]))\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "        df2 = pd.DataFrame(list(zip(sections,created,model,DrawColors,user,assistant,prompt_tokens,completion_tokens,total_tokens)),columns =['sections','created','model','DrawColors','user','assistant','prompt_tokens','completion_tokens','total_tokens'])\n",
    "\n",
    "\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "# Save to CSV format \n",
    "\n",
    "\n",
    "#df.to_csv(r'C:\\Users\\FLG\\Documents\\ChatGPTExperiments\\BayesianChatGPT23.csv', sep='#', index = False)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0de7b154-e180-4167-a910-c8f8d684625a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sections</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>DrawColors</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1708626918</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1708626930</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1708626942</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1708626953</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1708626965</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1708626977</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1708626990</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1708627003</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1708627015</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1708627026</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1708627038</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1708627050</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1708627062</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1708627073</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1708627084</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1708627095</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1708627106</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.7</td>\n",
       "      <td>1708627117</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.8</td>\n",
       "      <td>1708627129</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.9</td>\n",
       "      <td>1708627141</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1708627153</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1708627164</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1708627176</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.3</td>\n",
       "      <td>1708627187</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1708627198</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1708627209</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1708627221</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.7</td>\n",
       "      <td>1708627233</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1708627244</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.9</td>\n",
       "      <td>1708627307</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sections     created               model DrawColors  \\\n",
       "0      0.0  1708626918  gpt-4-1106-preview        Red   \n",
       "1      0.1  1708626930  gpt-4-1106-preview        Red   \n",
       "2      0.2  1708626942  gpt-4-1106-preview        Red   \n",
       "3      0.3  1708626953  gpt-4-1106-preview        Red   \n",
       "4      0.4  1708626965  gpt-4-1106-preview        Red   \n",
       "5      0.5  1708626977  gpt-4-1106-preview      Green   \n",
       "6      0.6  1708626990  gpt-4-1106-preview      Green   \n",
       "7      0.7  1708627003  gpt-4-1106-preview      Green   \n",
       "8      0.8  1708627015  gpt-4-1106-preview      Green   \n",
       "9      0.9  1708627026  gpt-4-1106-preview      Green   \n",
       "0      1.0  1708627038  gpt-4-1106-preview        Red   \n",
       "1      1.1  1708627050  gpt-4-1106-preview        Red   \n",
       "2      1.2  1708627062  gpt-4-1106-preview        Red   \n",
       "3      1.3  1708627073  gpt-4-1106-preview        Red   \n",
       "4      1.4  1708627084  gpt-4-1106-preview        Red   \n",
       "5      1.5  1708627095  gpt-4-1106-preview      Green   \n",
       "6      1.6  1708627106  gpt-4-1106-preview      Green   \n",
       "7      1.7  1708627117  gpt-4-1106-preview      Green   \n",
       "8      1.8  1708627129  gpt-4-1106-preview      Green   \n",
       "9      1.9  1708627141  gpt-4-1106-preview      Green   \n",
       "0      2.0  1708627153  gpt-4-1106-preview        Red   \n",
       "1      2.1  1708627164  gpt-4-1106-preview        Red   \n",
       "2      2.2  1708627176  gpt-4-1106-preview        Red   \n",
       "3      2.3  1708627187  gpt-4-1106-preview        Red   \n",
       "4      2.4  1708627198  gpt-4-1106-preview        Red   \n",
       "5      2.5  1708627209  gpt-4-1106-preview      Green   \n",
       "6      2.6  1708627221  gpt-4-1106-preview      Green   \n",
       "7      2.7  1708627233  gpt-4-1106-preview      Green   \n",
       "8      2.8  1708627244  gpt-4-1106-preview      Green   \n",
       "9      2.9  1708627307  gpt-4-1106-preview      Green   \n",
       "\n",
       "                                                user  \\\n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "\n",
       "                                assistant  prompt_tokens  completion_tokens  \\\n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "\n",
       "   total_tokens  \n",
       "0           287  \n",
       "1           360  \n",
       "2           438  \n",
       "3           519  \n",
       "4           603  \n",
       "5           690  \n",
       "6           780  \n",
       "7           873  \n",
       "8           969  \n",
       "9          1068  \n",
       "0           287  \n",
       "1           360  \n",
       "2           438  \n",
       "3           519  \n",
       "4           603  \n",
       "5           690  \n",
       "6           780  \n",
       "7           873  \n",
       "8           969  \n",
       "9          1068  \n",
       "0           287  \n",
       "1           360  \n",
       "2           438  \n",
       "3           519  \n",
       "4           603  \n",
       "5           690  \n",
       "6           780  \n",
       "7           873  \n",
       "8           969  \n",
       "9          1068  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d501484d-25a9-4f09-9bb3-582ad30699d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sections</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>DrawColors</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1708626918</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "      <td>67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1708626930</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1708626942</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1708626953</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "      <td>95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1708626965</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "      <td>97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1708626977</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1708626990</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1708627003</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1708627015</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1708627026</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1708627038</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "      <td>67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1708627050</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1708627062</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1708627073</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "      <td>95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1708627084</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "      <td>97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1708627095</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1708627106</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.7</td>\n",
       "      <td>1708627117</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.8</td>\n",
       "      <td>1708627129</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.9</td>\n",
       "      <td>1708627141</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1708627153</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "      <td>67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1708627164</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1708627176</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.3</td>\n",
       "      <td>1708627187</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "      <td>95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1708627198</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "      <td>97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1708627209</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1708627221</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.7</td>\n",
       "      <td>1708627233</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1708627244</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.9</td>\n",
       "      <td>1708627307</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sections     created               model DrawColors  \\\n",
       "0      0.0  1708626918  gpt-4-1106-preview        Red   \n",
       "1      0.1  1708626930  gpt-4-1106-preview        Red   \n",
       "2      0.2  1708626942  gpt-4-1106-preview        Red   \n",
       "3      0.3  1708626953  gpt-4-1106-preview        Red   \n",
       "4      0.4  1708626965  gpt-4-1106-preview        Red   \n",
       "5      0.5  1708626977  gpt-4-1106-preview      Green   \n",
       "6      0.6  1708626990  gpt-4-1106-preview      Green   \n",
       "7      0.7  1708627003  gpt-4-1106-preview      Green   \n",
       "8      0.8  1708627015  gpt-4-1106-preview      Green   \n",
       "9      0.9  1708627026  gpt-4-1106-preview      Green   \n",
       "0      1.0  1708627038  gpt-4-1106-preview        Red   \n",
       "1      1.1  1708627050  gpt-4-1106-preview        Red   \n",
       "2      1.2  1708627062  gpt-4-1106-preview        Red   \n",
       "3      1.3  1708627073  gpt-4-1106-preview        Red   \n",
       "4      1.4  1708627084  gpt-4-1106-preview        Red   \n",
       "5      1.5  1708627095  gpt-4-1106-preview      Green   \n",
       "6      1.6  1708627106  gpt-4-1106-preview      Green   \n",
       "7      1.7  1708627117  gpt-4-1106-preview      Green   \n",
       "8      1.8  1708627129  gpt-4-1106-preview      Green   \n",
       "9      1.9  1708627141  gpt-4-1106-preview      Green   \n",
       "0      2.0  1708627153  gpt-4-1106-preview        Red   \n",
       "1      2.1  1708627164  gpt-4-1106-preview        Red   \n",
       "2      2.2  1708627176  gpt-4-1106-preview        Red   \n",
       "3      2.3  1708627187  gpt-4-1106-preview        Red   \n",
       "4      2.4  1708627198  gpt-4-1106-preview        Red   \n",
       "5      2.5  1708627209  gpt-4-1106-preview      Green   \n",
       "6      2.6  1708627221  gpt-4-1106-preview      Green   \n",
       "7      2.7  1708627233  gpt-4-1106-preview      Green   \n",
       "8      2.8  1708627244  gpt-4-1106-preview      Green   \n",
       "9      2.9  1708627307  gpt-4-1106-preview      Green   \n",
       "\n",
       "                                                user  \\\n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "\n",
       "                                assistant  prompt_tokens  completion_tokens  \\\n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "\n",
       "   total_tokens Estimate  \n",
       "0           287      67%  \n",
       "1           360      80%  \n",
       "2           438      90%  \n",
       "3           519      95%  \n",
       "4           603      97%  \n",
       "5           690      85%  \n",
       "6           780      75%  \n",
       "7           873      65%  \n",
       "8           969      50%  \n",
       "9          1068      40%  \n",
       "0           287      67%  \n",
       "1           360      80%  \n",
       "2           438      90%  \n",
       "3           519      95%  \n",
       "4           603      97%  \n",
       "5           690      85%  \n",
       "6           780      75%  \n",
       "7           873      65%  \n",
       "8           969      50%  \n",
       "9          1068      40%  \n",
       "0           287      67%  \n",
       "1           360      80%  \n",
       "2           438      90%  \n",
       "3           519      95%  \n",
       "4           603      97%  \n",
       "5           690      85%  \n",
       "6           780      75%  \n",
       "7           873      65%  \n",
       "8           969      50%  \n",
       "9          1068      40%  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Extract with Regular Expression\n",
    "df['Estimate'] = df['assistant'].str.extract(r'(\\d+(?:\\.\\d+)?%)', expand=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4dce5a-e6fc-4f0a-a33c-dd74c2bb7d2e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f11ad056-40b0-4b00-92fd-557eb690711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to numeric values\n",
    "df['sections'] = df['sections'].astype(str)\n",
    "# Split the values into two columns based on the decimal point\n",
    "df[['session', 'sub_session']] = df['sections'].str.split('.', expand=True)\n",
    "\n",
    "# Convert the columns to numeric \n",
    "df['session'] = pd.to_numeric(df['session'])\n",
    "df['sub_session'] = pd.to_numeric(df['sub_session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bc07e97c-039a-40f9-ad3e-7821bc0dca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sections</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>DrawColors</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>session</th>\n",
       "      <th>sub_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1708626918</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "      <td>67%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1708626930</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>80%</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1708626942</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "      <td>90%</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1708626953</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "      <td>95%</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1708626965</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "      <td>97%</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1708626977</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "      <td>85%</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1708626990</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "      <td>75%</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1708627003</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "      <td>65%</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1708627015</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "      <td>50%</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1708627026</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "      <td>40%</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1708627038</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "      <td>67%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1708627050</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>80%</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>1708627062</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "      <td>90%</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1708627073</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "      <td>95%</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1708627084</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "      <td>97%</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1708627095</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "      <td>85%</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1708627106</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "      <td>75%</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.7</td>\n",
       "      <td>1708627117</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "      <td>65%</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.8</td>\n",
       "      <td>1708627129</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "      <td>50%</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.9</td>\n",
       "      <td>1708627141</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "      <td>40%</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1708627153</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "      <td>67%</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1</td>\n",
       "      <td>1708627164</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>80%</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1708627176</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "      <td>90%</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.3</td>\n",
       "      <td>1708627187</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 4: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 95%.</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>519</td>\n",
       "      <td>95%</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.4</td>\n",
       "      <td>1708627198</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 5: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 97%.</td>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>603</td>\n",
       "      <td>97%</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1708627209</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 6: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 85%.</td>\n",
       "      <td>681</td>\n",
       "      <td>9</td>\n",
       "      <td>690</td>\n",
       "      <td>85%</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1708627221</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 7: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 75%.</td>\n",
       "      <td>771</td>\n",
       "      <td>9</td>\n",
       "      <td>780</td>\n",
       "      <td>75%</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.7</td>\n",
       "      <td>1708627233</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 8: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 65%.</td>\n",
       "      <td>864</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "      <td>65%</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1708627244</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 9: Green (recall; the sequence of previou...</td>\n",
       "      <td>My best guess would be around 50%.</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>969</td>\n",
       "      <td>50%</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.9</td>\n",
       "      <td>1708627307</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Green</td>\n",
       "      <td>Draw 10: Green (recall; the sequence of previo...</td>\n",
       "      <td>My best guess would be around 40%.</td>\n",
       "      <td>1059</td>\n",
       "      <td>9</td>\n",
       "      <td>1068</td>\n",
       "      <td>40%</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sections     created               model DrawColors  \\\n",
       "0      0.0  1708626918  gpt-4-1106-preview        Red   \n",
       "1      0.1  1708626930  gpt-4-1106-preview        Red   \n",
       "2      0.2  1708626942  gpt-4-1106-preview        Red   \n",
       "3      0.3  1708626953  gpt-4-1106-preview        Red   \n",
       "4      0.4  1708626965  gpt-4-1106-preview        Red   \n",
       "5      0.5  1708626977  gpt-4-1106-preview      Green   \n",
       "6      0.6  1708626990  gpt-4-1106-preview      Green   \n",
       "7      0.7  1708627003  gpt-4-1106-preview      Green   \n",
       "8      0.8  1708627015  gpt-4-1106-preview      Green   \n",
       "9      0.9  1708627026  gpt-4-1106-preview      Green   \n",
       "0      1.0  1708627038  gpt-4-1106-preview        Red   \n",
       "1      1.1  1708627050  gpt-4-1106-preview        Red   \n",
       "2      1.2  1708627062  gpt-4-1106-preview        Red   \n",
       "3      1.3  1708627073  gpt-4-1106-preview        Red   \n",
       "4      1.4  1708627084  gpt-4-1106-preview        Red   \n",
       "5      1.5  1708627095  gpt-4-1106-preview      Green   \n",
       "6      1.6  1708627106  gpt-4-1106-preview      Green   \n",
       "7      1.7  1708627117  gpt-4-1106-preview      Green   \n",
       "8      1.8  1708627129  gpt-4-1106-preview      Green   \n",
       "9      1.9  1708627141  gpt-4-1106-preview      Green   \n",
       "0      2.0  1708627153  gpt-4-1106-preview        Red   \n",
       "1      2.1  1708627164  gpt-4-1106-preview        Red   \n",
       "2      2.2  1708627176  gpt-4-1106-preview        Red   \n",
       "3      2.3  1708627187  gpt-4-1106-preview        Red   \n",
       "4      2.4  1708627198  gpt-4-1106-preview        Red   \n",
       "5      2.5  1708627209  gpt-4-1106-preview      Green   \n",
       "6      2.6  1708627221  gpt-4-1106-preview      Green   \n",
       "7      2.7  1708627233  gpt-4-1106-preview      Green   \n",
       "8      2.8  1708627244  gpt-4-1106-preview      Green   \n",
       "9      2.9  1708627307  gpt-4-1106-preview      Green   \n",
       "\n",
       "                                                user  \\\n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "3  Draw 4: Red (recall; the sequence of previous ...   \n",
       "4  Draw 5: Red (recall; the sequence of previous ...   \n",
       "5  Draw 6: Green (recall; the sequence of previou...   \n",
       "6  Draw 7: Green (recall; the sequence of previou...   \n",
       "7  Draw 8: Green (recall; the sequence of previou...   \n",
       "8  Draw 9: Green (recall; the sequence of previou...   \n",
       "9  Draw 10: Green (recall; the sequence of previo...   \n",
       "\n",
       "                                assistant  prompt_tokens  completion_tokens  \\\n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "3      My best guess would be around 95%.            510                  9   \n",
       "4      My best guess would be around 97%.            594                  9   \n",
       "5      My best guess would be around 85%.            681                  9   \n",
       "6      My best guess would be around 75%.            771                  9   \n",
       "7      My best guess would be around 65%.            864                  9   \n",
       "8      My best guess would be around 50%.            960                  9   \n",
       "9      My best guess would be around 40%.           1059                  9   \n",
       "\n",
       "   total_tokens Estimate  session  sub_session  \n",
       "0           287      67%        0            0  \n",
       "1           360      80%        0            1  \n",
       "2           438      90%        0            2  \n",
       "3           519      95%        0            3  \n",
       "4           603      97%        0            4  \n",
       "5           690      85%        0            5  \n",
       "6           780      75%        0            6  \n",
       "7           873      65%        0            7  \n",
       "8           969      50%        0            8  \n",
       "9          1068      40%        0            9  \n",
       "0           287      67%        1            0  \n",
       "1           360      80%        1            1  \n",
       "2           438      90%        1            2  \n",
       "3           519      95%        1            3  \n",
       "4           603      97%        1            4  \n",
       "5           690      85%        1            5  \n",
       "6           780      75%        1            6  \n",
       "7           873      65%        1            7  \n",
       "8           969      50%        1            8  \n",
       "9          1068      40%        1            9  \n",
       "0           287      67%        2            0  \n",
       "1           360      80%        2            1  \n",
       "2           438      90%        2            2  \n",
       "3           519      95%        2            3  \n",
       "4           603      97%        2            4  \n",
       "5           690      85%        2            5  \n",
       "6           780      75%        2            6  \n",
       "7           873      65%        2            7  \n",
       "8           969      50%        2            8  \n",
       "9          1068      40%        2            9  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "05562e06-8fb7-4617-9026-5f5383a36b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>DrawColors</th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Red</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Green</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session DrawColors  red  green\n",
       "0        0        Red    1      0\n",
       "1        0        Red    2      0\n",
       "2        0        Red    3      0\n",
       "3        0        Red    4      0\n",
       "4        0        Red    5      0\n",
       "5        0      Green    5      1\n",
       "6        0      Green    5      2\n",
       "7        0      Green    5      3\n",
       "8        0      Green    5      4\n",
       "9        0      Green    5      5\n",
       "0        1        Red    1      0\n",
       "1        1        Red    2      0\n",
       "2        1        Red    3      0\n",
       "3        1        Red    4      0\n",
       "4        1        Red    5      0\n",
       "5        1      Green    5      1\n",
       "6        1      Green    5      2\n",
       "7        1      Green    5      3\n",
       "8        1      Green    5      4\n",
       "9        1      Green    5      5\n",
       "0        2        Red    1      0\n",
       "1        2        Red    2      0\n",
       "2        2        Red    3      0\n",
       "3        2        Red    4      0\n",
       "4        2        Red    5      0\n",
       "5        2      Green    5      1\n",
       "6        2      Green    5      2\n",
       "7        2      Green    5      3\n",
       "8        2      Green    5      4\n",
       "9        2      Green    5      5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape data to calculate Bayes' rule (posterior probability of Red)\n",
    "df['red'] = df.groupby('session')['DrawColors'].transform(lambda x: x.eq('Red').cumsum())\n",
    "df['green'] = df.groupby('session')['DrawColors'].transform(lambda x: x.eq('Green').cumsum())\n",
    "df[['session','DrawColors','red','green']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0422c9f9-0b21-4302-a857-177f9bdb98a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sections</th>\n",
       "      <th>created</th>\n",
       "      <th>model</th>\n",
       "      <th>DrawColors</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>session</th>\n",
       "      <th>sub_session</th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>theoritical_posterior_prob</th>\n",
       "      <th>ChatGPT_posterior_prob</th>\n",
       "      <th>diff_posterior_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1708626918</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Now, I would like to give me your estimate for...</td>\n",
       "      <td>My best guess would be around 67%.</td>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>287</td>\n",
       "      <td>67%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>67</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1708626930</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 2: Red (recall; the first draw was Red). ...</td>\n",
       "      <td>My best guess now would be around 80%.</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>80%</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1708626942</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>Red</td>\n",
       "      <td>Draw 3: Red (recall; the sequence of previous ...</td>\n",
       "      <td>My best guess would be around 90%.</td>\n",
       "      <td>429</td>\n",
       "      <td>9</td>\n",
       "      <td>438</td>\n",
       "      <td>90%</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>90</td>\n",
       "      <td>-1.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sections     created               model DrawColors  \\\n",
       "0      0.0  1708626918  gpt-4-1106-preview        Red   \n",
       "1      0.1  1708626930  gpt-4-1106-preview        Red   \n",
       "2      0.2  1708626942  gpt-4-1106-preview        Red   \n",
       "\n",
       "                                                user  \\\n",
       "0  Now, I would like to give me your estimate for...   \n",
       "1  Draw 2: Red (recall; the first draw was Red). ...   \n",
       "2  Draw 3: Red (recall; the sequence of previous ...   \n",
       "\n",
       "                                assistant  prompt_tokens  completion_tokens  \\\n",
       "0      My best guess would be around 67%.            278                  9   \n",
       "1  My best guess now would be around 80%.            350                 10   \n",
       "2      My best guess would be around 90%.            429                  9   \n",
       "\n",
       "   total_tokens Estimate  session  sub_session  red  green  \\\n",
       "0           287      67%        0            0    1      0   \n",
       "1           360      80%        0            1    2      0   \n",
       "2           438      90%        0            2    3      0   \n",
       "\n",
       "   theoritical_posterior_prob  ChatGPT_posterior_prob  diff_posterior_prob  \n",
       "0                   66.666667                      67            -0.333333  \n",
       "1                   80.000000                      80             0.000000  \n",
       "2                   88.888889                      90            -1.111111  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function for the formula calculation\n",
    "def calculate_posterior_prob(row):\n",
    "    return (2**row['red'] / (2**row['red'] + 2**row['green']))*100\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "df['theoritical_posterior_prob'] = df.apply(lambda row: calculate_posterior_prob(row), axis=1)\n",
    "\n",
    "# from string var to numeric var\n",
    "df['ChatGPT_posterior_prob'] = pd.to_numeric(df['Estimate'].str.replace('%', ''))\n",
    "\n",
    "# dif between theoritical_posterior_prob and ChatGPT_posterior_prob\n",
    "def diff_posterior_prob(row):\n",
    "    return (row['theoritical_posterior_prob'] - row['ChatGPT_posterior_prob'])\n",
    "df['diff_posterior_prob'] = df.apply(lambda row: diff_posterior_prob(row), axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "#df[['sections','DrawColors','red','green','theoritical_posterior_prob','Estimate','ChatGPT_posterior_prob','diff_posterior_prob']].head(5)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b2fe84d-2340-47bd-8ef4-69daf01776ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Group by 'Group' and plot each line\n",
    "for group, group_data in df.groupby('session'):\n",
    "    group_data.plot(x='sub_session', y='ChatGPT_posterior_prob', label=group, ax=ax)\n",
    "    \n",
    "for group, group_data in df.groupby('session'):\n",
    "    group_data.plot(x='sub_session', y='theoritical_posterior_prob', label=group, ax=ax)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Draw')\n",
    "plt.ylabel('Probability Mostly-Red bag')\n",
    "plt.title('Line Plot by Group')\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401ddb7-addb-4fa4-8d3d-1ceaeb4e8a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
