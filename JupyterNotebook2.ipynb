{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For openai >= 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The openai.ChatCompletion.create() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access environment variables\n",
    "import os\n",
    "from openai import OpenAI  #(new code)\n",
    "\n",
    "client = OpenAI(api_key=\"********************\",)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        #model=\"gpt-4-1106-preview\",\n",
    "        temperature=0.6,\n",
    "        max_tokens=200,\n",
    "        top_p=0.2,\n",
    "        n=2,\n",
    "        frequency_penalty=0.6,\n",
    "        presence_penalty=0.8,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical. Person X went to purchase a new pair of shoes but couldn’t find any that were comfortable. Rating ?\"}]\n",
    "     )\n",
    "print(completion.choices[0].message.content.strip())\n",
    "\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "#print(completion.choices[0])\n",
    "#print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how 'completion.choices[0].message' works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message)\n",
    "#print(completion.choices[0])\n",
    "#print(completion)\n",
    "#print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the 'System'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = '*******************************'\n",
    "#*********************************************************************************************\n",
    "\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "messages.append({\"role\": \"system\", \"content\": \"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\"})\n",
    "\n",
    "# Le message\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X risked their life rescuing an animal that was trapped inside a burning house. Rating ?\"})\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three possible roles: 'system' (the profile/context given to ChatGPT), 'user' (you), 'assistant' (the responses from ChatGPT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages)\n",
    "#print(messages[0])\n",
    "#print(messages[1])\n",
    "#print(completion.choices[0].message.content)\n",
    "#print(completion.choices[0].message.role)\n",
    "#print(completion.choices[0].message)\n",
    "#print(completion.choices[0])\n",
    "#print(completion.choices)\n",
    "#print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '****************'\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "messages.append({\"role\": \"system\", \"content\": \"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\"})\n",
    "\n",
    "# Le message\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X risked their life rescuing an animal that was trapped inside a burning house.\"})\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  #model=\"gpt-4-1106-preview\",\n",
    "  temperature=1,\n",
    "  max_tokens=200,\n",
    "  top_p=0.2,\n",
    "  n=2,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices)\n",
    "#print(completion.choices[0].message.content)\n",
    "#print(completion.choices[1].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add parameters (frequency_penalty, presence_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '****************'\n",
    "# On déclare une liste pour conserver l'historique de tous nos messages avec ChatGPT\n",
    "messages = []\n",
    "\n",
    "# optionnel, permet de définir le comportement que l'assistant doit adopter\n",
    "messages.append({\"role\": \"system\", \"content\": \"For each action below, I will rate on a scale of -4 to 4 how unethical or ethical it is. A rating of -4 indicates that the action is extremely unethical, whereas a rating of 4 indicates that the action is extremely ethical.\"})\n",
    "\n",
    "# Le message\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X risked their life rescuing an animal that was trapped inside a burning house.\"})\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  #model=\"gpt-4-1106-preview\",\n",
    "  temperature=0.6,\n",
    "  max_tokens=200,\n",
    "  top_p=0.2,\n",
    "  n=2,\n",
    "  frequency_penalty=0.6,\n",
    "  presence_penalty=0.8,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory effect: now, we are incorporating the previous responses from ChatGPT. (Nn, the variable 'messages' becoming a list of dictionnaries), e.g. [{1:'text1'}, {'text2':'text3'}, {'text4':2},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '****************'\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Person X drove their car the wrong way down a one-way street. Rating ?\"})\n",
    "# nb: messages = list of dictionnaries\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0.6,\n",
    "  max_tokens=50,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages\n",
    "#messages[0]\n",
    "#messages[1]\n",
    "#messages[2]\n",
    "#messages[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in messages:\n",
    "    print(d['role'])\n",
    "for d in messages:\n",
    "    print(d['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '****************'\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_chatgpt})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Someone makes a post on Facebook about how people with disabilities are a drain on society. Rating ?\"})\n",
    "# nb: messages = list of dictionnaries\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0.6,\n",
    "  max_tokens=50,\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "response_chatgpt = completion.choices[0].message.content\n",
    "\n",
    "print(response_chatgpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages\n",
    "#messages[0]\n",
    "#messages[1]\n",
    "#messages[2]\n",
    "#messages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in messages:\n",
    "    print(d['role'])\n",
    "for d in messages:\n",
    "    print(d['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_messages = [d.get('content') for d in messages if d['role']=='assistant']  \n",
    "print(sub_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_messages = [d.get('content') for d in messages if d['role']=='user']  \n",
    "print(sub_messages)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
